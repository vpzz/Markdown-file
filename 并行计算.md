# 基础

1. 多处理器的加速比=使用单个处理器计算所消耗的时间/使用多个处理器计算所消耗的时间。
2. 多个处理器各自计算的结果需要汇总或相互交流，这限制了达成完美的加速比。
3. 任务分配不均匀也会导致某些处理器等待其他处理器的情况。静态负载均衡是在开始前分配，动态负载均衡在运行时也可以调配负载，不过会产生开销。
4. 如果将任务分配的过于细小，则CPU之间交流占用时间会比实际计算的时间要长，也会限制加速比。
5. Flop：Floating point operation，通常指双精度浮点计算。随着深度学习的引入，16，8位浮点数越来越常见。
6. 超级计算机IBM Summit，理论峰值为200PFlop/s，实测峰值为148.6PFlop/s。性能是通过Linpack库测出来，包括通过LU分解法求解大规模非稀疏，系数随机的线性方程组。Linpack是比较理想化的，实测峰值可以达到理论峰值的70%，实际问题中，大约10%不到。
7. 早期的超级计算机就是一台超级大的计算机，多个处理器通过共享内存相互协作，现代的超级计算机都是很多台计算机，他们之间通过超高速网络相连接，多个计算节点组成的集群，MPI也是这时期发展来的。再往后就变成异构了，CPU和GPU都存在。
8. Seymour Roger Cray是超级计算机之父，他说过：任何人都可以构建一个快的处理器，而构建一个快的系统是困难的。系统涉及处理器，软件，算法等。
9. 第一台超级计算机CDC6600。比当时最快的计算机快10倍，浮点性能为3MFlop/s。
10. 国内超算的派系：曙光（中科院计算所），银河/天河（国防科大），神威（无锡江南计算所）
11. 1996年中国宣布禁止核试验后，对于超算的需求更大了。
12. 目前x86指令集在超算领域已经一家独大了。
13. 并行和并发的区别：
    1. 并行，Parallelism，指的是多个子任务同时运行，控制流的状态。需要考虑内存一致性。
    2. 并发，Concurrency，指的是控制流的一种同时运行的属性，需要考虑信号处理。
14. 任务并行和数据并行的区别，用于切分的对象不同，前者是任务，后者是数据。有时并没有严格的界限。
15. 两类并行编程模式，根据对内存的访问方式来区分：
    1. 共享内存并行编程，数据天然就是共享的，不过对数据的访问需要手动同步。Pthread就是这种，它是一种偏底层的方式。OpenMP也是，简化了很多，借助于编译器来节省很多代码的编写，自动生成。
    2. 分布式内存并行编程，相对更难点，数据共享和通讯都需要手动完成。通过消息传递方式，MPI就是这种。
16. 并行程序的调试比较麻烦，工具可能不一定好用，多用printf，人工调试。
17. 提高处理器的数量，只能加速程序中并行的部分，不可并行的部分不受影响。
18. 并行计算中的开销有：开启新线程或进程的开销，交换共享数据的开销，同步访问中等待的开销，冗余计算的开销。
19. Flynn分类法，根据指令是如何处理数据，可以分为：
    1. SISD，单指令单数据模型，可以通过流水线来提高性能。
    2. SIMD，单指令多数据模型，也称为向量机，SSE，AVX指令都是这种。
    3. MISD
    4. MIMD
20. 
21. 
22. 
23. 
24. 
25. 
26. 
27. 
28. 
29. 
30. 
31. 
32. 
33. 
34. 
35. 
36. 
37. 
38. 
39. 
40. 
41. 
42. 
43. 
44. 
45. 
46. 
47. 
48. 
49. 
50. 
51. 
52. 
53. 
54. 
55. 
56. 
57. 
58. 
59. 
60. 
61. 
62. 
63. 
64. 
65. 