# 线性空间

1. 线性空间：对于非空集合V和域F：
   1. 若存在映射$\sigma:V\times V\to V$，则称$\sigma$为V上的加法。$\times$是两个集合的笛卡尔积操作，也就是有两个集合的任意两个元素组成的有序对$(V_1,V_2)$的集合。$\to$为映射的记号，左右都是集合。有序对也成为元组。
   2. 若存在映射$\tau:V\times F\to V$，则称$\tau$为V和F之间的数量乘法。
   3. 且上述两种运算满足通常的运算规则（加法4条，加法和数乘之间有4条），则称$V$构成$F$上的线性空间。
2. 线性空间也被称为向量空间，$V$中的元素也被称为向量。所有的线性空间都含有无穷多个元素，除了只含有零向量的那个线性空间，因为域F一般是无限的。
3. $\to$和$\mapsto$是不同的，前者两侧是集合，后者两侧是元素。例如$\sin(\cdot)$这个函数将$(-\infty,+\infty)\to [-1,1]$，而将元素$\pi \mapsto 0$。前面的那个$[-1,1]$也可以是任意包含值域的区间。
4. 域是一种特殊的集合，定义了加法和乘法两种运算，且它们满足一些性质，如加法和乘法的逆运算在这个集合中可以进行（封闭）。也就是说域中定义了加减乘除四种运算。
5. 一些数的记号：$Z$整数，$Z_+$非负整数，$Q$有理数，$R$实数，$C$复数。
6. $Q,R,C$ 都可以构成一个域，而$Z$和$Z_+$都不是域。任意有理数都可以写成两个整数的比，也就是真分数或假分数。毕达哥拉斯的学生对于无理数的发现也造成了第一次数学危机。
7. 集合V和域F的数乘有两种写法，$V\times F$或$F\times V$。使用右乘可以和列向量兼容，例如向量$v=[1,2,3]^T$和数2相乘，可以将数2看作一个$1\times 1$的矩阵，这样是满足矩阵乘法的规则的。如果向量是列向量，那么数乘应该使用左乘。这样编程可以方便。
8. 常见的线性空间：
   1. 数域$F$上的标准线性空间$F^n$，其中$V:=F\times F\times \cdots \times F$，一共n个，也就是F构成的n元组。
   2. 几何空间作为线性空间。V是几何空间中所有的有向线段，其中如果可以通过平移重合的有向线段视为同一个。这是将线性空间称之为空间的原因。
   3. 所有的一元向量值函数$F(I,R^n)$也构成一个线性空间，也叫做函数空间。定义域为$I$，将I映射到$R^n$中。
   3. $F^{m\times n}$表示域$F$上m行n列的矩阵的全体，这也构成一个线性空间，维数=$m\times n$。
9. $A:=B$表示将A定义为B。

# 极大无关子组

1. 向量组：线性空间$V$中有限个向量$\alpha_1,\alpha_2\cdots,\alpha_p$构成的序列。向量组拼成的抽象矩阵：$[\alpha_1,\alpha_2\cdots,\alpha_p]$，1行p列。通常的矩阵是由数构成的。这里之所以横着拼，是因为将来的向量默认使用列向量。
2. 向量组的线性相关性：如果存在不全为0的p个数，使得线性组合$\alpha_1k_1+\alpha_2k_2+\cdots+\alpha_pk_p=0$，那就成这个向量组线性相关，这里的0指的是线性空间中的0向量。也就是说如果向量组线性相关，那么上面的线性组合构成的齐次线性方程组有非零解。
3. 一个向量$\beta$可以由另一个向量组$\alpha_1,\alpha_2\cdots,\alpha_p$线性表示，这意味着由该向量作为右端项和向量组作为系数矩阵的非齐次线性方程组有解。
4. 如果一个向量组$\beta_1,\beta_2,\cdots,\beta_q$中的每个向量都可以由另一个向量组$\alpha_1,\alpha_2\cdots,\alpha_p$的线性组合表示，那么称向量组$\beta_1,\beta_2,\cdots,\beta_q$可以有向量$\alpha_1,\alpha_2\cdots,\alpha_p$线性表示。
5. $[\alpha_1,\alpha_2,\cdots,\alpha_p]_{1\times p}\begin{bmatrix}x_{11}&x_{12}&\cdots&x_{1q}\\x_{21}&x_{22}&\cdots&x_{2q}\\ \vdots &\vdots &\ddots &\vdots\\x_{p1}&x_{p2}&\cdots& x_{pq} \end{bmatrix}_{p\times q}=[\beta_1,\beta_2，\cdots,\beta_q]_{1\times q}$。得出$AX=B$这一抽象的矩阵方程，其中X是一个真正的矩阵，A和B都是抽象矩阵。上述线性表示意味着上面的矩阵方程有解。
6. 线性表示关系具有传递性，如果B可以由A线性表示，C可以由B线性表示，那么C可以由A线性表示。
7. 向量组的子组就是从原向量组中抽出一些向量来，仍按照原来的顺序构成的新向量组。
8. 向量组的极大线性无关子组，极大就是不能再大了，如果再加入原向量组中的任意一个向量都会使得该子组变为线性相关。也可以用生成性来解释，该子组可以线性表示原向量组。因此向量组的极大线性无关子组也成为其生成组。
9. 向量组的极大线性无关子组一般是不唯一的，但是所有生成组的向量个数是相同的，这个数称为向量组的秩。
10. 如果齐次线性方程组的系数矩阵是扁的(行数<列数)，那么必有非零解。也就是方程的个数<未知数的个数，称为不定方程组。

# 基

1. 线性空间V的基（也就是坐标系）是其中的一个向量组$\{\alpha_i\}$，该向量组由n个向量。需要满足两条性质：
   1. 向量组$\{\alpha_i\}$线性无关。
   2. V中的任意一个向量$\alpha$都可以由向量组$\{\alpha_i\}$线性表示，$\alpha=\alpha_1k_1+\alpha_2k_2+\cdots+\alpha_nk_n$。
2. 同时也称V是有限维即n维线性空间。任意向量的线性组合的系数$k_i$也成为该向量在基$\{\alpha_i\}$下的坐标。$[k_1,k_2,\cdots,k_n]^T\in F^n$也被称为该向量的坐标向量。
3. $\begin{bmatrix}抽\\象\\向\\量  \end{bmatrix}=\begin{bmatrix}抽象基矩阵 \end{bmatrix}*\begin{bmatrix}坐\\标\\向\\量\end{bmatrix}$，抽象向量是V中的，抽象基矩阵是由基向量拼成的，坐标向量是$F^n$中的向量，纯数字。
4. 上面的向量组$\{\alpha_i\}$可以看作一个基，而不是一组基。
5. 线性空间的基不唯一，但是基的元素个数相同，称为线性空间$A$的维数，记作$dim(A)$。
6. 基实现了从抽象线性空间到标准线性空间的一一对应。
6. 一一对应是满射（任意一个像都有原像与之对应）+单射（像的原像只有一个或0个，不能是多对一）。加起来就是任意一个像都有且只有1个原像与之对应。一一映射存在逆映射，也称为双射。
6. 两个集合之间如果存在一个双射，则称这两个集合是等价的。
7. 两个线性空间若存在一个一一对应的线性映射$\sigma$，则称$\sigma$为同构。同构之于线性空间就像一一对应之于集合。同构就是保持加法和数乘的双射。
7. 任意$n$维线性空间都同构于$F^n$，该映射将线性空间中的向量映射为任意一组基的坐标表示。因此$n$维线性空间实际上只有一个。这也是线性空间可以称为向量空间的原因，抽象→具体。
8. $F^n$的标准基：$e_1=[1,0,\cdots,0]^T$，$e_2=[0,1,\cdots,0]^T$，$\cdots$，$e_n=[0,0,\cdots,1]^T$。标准基向量拼成的矩阵是单位矩阵。一般基拼成的矩阵是可逆矩阵。
9. $F^n$中的向量在标准基下的坐标向量就是他自己。
10. 从n维线性空间中选出1个n元的向量组，如果该向量组是线性无关的，那么它就构成该线性空间的一个基。生成性蕴含在其中。
11. 矩阵的秩相关概念：
    1. 矩阵的秩是其中不为0的子行列式的最大阶数。
    2. 行秩：矩阵的行向量组的极大线性无关子组的向量个数。也就是说将该矩阵看作由一系列行向量组合而成的。
    3. 列秩：矩阵的列向量组的极大线性无关子组的向量个数。
    4. 矩阵的秩=行秩=列秩，这是由于$\rank(A)=\rank(A^T)$。
    4. 方阵的秩=非零特征值的个数
12. 列满秩表示列秩等于列数，行满秩同理。对于方阵才可以谈论满秩，方针的满秩$\Leftrightarrow$列满秩$\Leftrightarrow$行满秩。矩阵满秩$\Leftrightarrow$可逆$\Leftrightarrow$非奇异。
12. 非齐次线性方程组$Ax=b$是否有解  $\Leftrightarrow$  $A$的列向量组能否线性表示$b$。
13. 齐次线性方程组$Ax=0$是否由非零解  $\Leftrightarrow$  $A$的列向量组是否线性无关。
14. $F[x]$表示数域F中以$x$为自变量的多项式的全体，自变量和因变量都在$F$内，它是无限维的。$F_n[x]$是次数<n的F上多项式的全体，它是n维的，$1,x,x^2,\cdots,x^{n-1}$可以作为它的一个基，在证明其线性无关性时需要用到范德蒙行列式的值不为0这一结论。
15. 多项式函数的全体不是有限维的，因为任给N个多项式，总会找到一个多项式（次数比它们高即可）不能由它们线性表示。

# 子空间

1. 线性空间$V$有一个非空子集合$W$，满足两个属性即称$W$时$V$的一个子空间：
   1. 对加法封闭，即在$W$中任取两个元素，做加法的结果仍在$W$中。
   2. 对数乘封闭，即在$W$中任取一个元素，在数域F中任取一个数，做数乘的结果仍在$W$中。
2. 子空间$W$按照$V$中的加法和数乘定义，也构成$F$上的一个线性空间。
3. 线性空间的任一子集不一定是子空间：取$V$为平面上起点重合的所有有向线段的全体，在平面上画一条不过该起点的直线，$W$为起点重合，终点落在该直线上的所有有向线段的全体。可以发现$W$中的有向线段对于加法和数乘不满足封闭性。
4. 向量组生成的子空间：线性空间$V$中的一个向量组$\alpha_1,\alpha_2,\cdots,\alpha_p$所生成的子空间记作$span\{\alpha_1,\alpha_2,\cdots,\alpha_p\}$。向量组的全体线性组合$\alpha_1k_1+\alpha_2k_2+\cdots+\alpha_pk_p$构成它张成的子空间。
5. 子空间的生成组：给定一个线性空间$V$的子空间$W$，如果存在一个向量组$\alpha_1,\alpha_2,\cdots,\alpha_p$，使得$span\{\alpha_1,\alpha_2,\cdots,\alpha_p\}=W$，那么称该向量组为子空间的生成组。
6. $\{x|Ax=b\},A\in F^{m\times n}$，所有$x$构成$F^n$的子空间。齐次线性方程组$Ax=b$的解空间称为$A$的核，记作$ker(A)$。
7. $\{Ax|x\in F^n\}$，也构成$F^n$的子空间，称为$A$的像空间，记作$im(A)$。这就是$A$的列向量组张成的空间$span\{\alpha_1,\cdots,\alpha_n \}$。$\{\alpha_1,\cdots,\alpha_n \}$为$A$的列向量组。
8. 子空间$U,W$的交也是原空间的一个子空间。
8. 子空间$U,W$的和定义为：$U+W=span\{U\cup W\}=\{u+w|u\in U,w\in W\}$是一个子空间。下图中$U,W$的和就是整个平面。子空间的和包含子空间的并(当另一个集合中的元素为零向量时)，还包含了很多由子空间中向量加出来的不在原来两个子空间的向量。也就是说两个子空间的和就是子空间的并生成的子空间。
9. 子空间$U,W$的并$U\cup W$（单纯就是$U,W$这两个集合的并集）不一定是子空间，因为对于加法不一定封闭。如下图，$w\in W,u\in U$，但是$w+u\notin W$或$U$。
10. <img src="矩阵分析.assets/image-20220224211442092.png" alt="image-20220224211442092" style="zoom:50%;" />
10. 子空间的直和$U\oplus W$（和的一种特殊情况）：$U,W$分别子空间，如果$U\cap W={0}$，则称二者的和为直和，记作$U\oplus W$。例如$xy$平面和$z$轴的和就是直和，$x$轴和$y$轴的和也是直和。直和并不要求结果必须是全空间。
10. 直和情况下，$U\oplus W$中的向量的分解是唯一的。即若$\alpha\in U\oplus W$，则存在唯一的$u\in U,w\in W$，使得$\alpha=u+w$。同时直和空间中的零向量只能分解为各自子空间中零向量的和。
10. 子空间直和的维数=子空间的维数的和。$\dim(U\oplus W)=\dim(U)+\dim(W)$这也是直和的判别条件。
10. 多个子空间两两之间的交为$\{0\}$，他们的和不一定为直和，例如下图所示，其中$(V_1\oplus V_2)\cap V_3\ne\{0\}$。
10. <img src="矩阵分析.assets/image-20220303100442939.png" alt="image-20220303100442939" style="zoom:80%;" />
10. 

# 线性映射与线性变换

1. $V_1$到$V_2$的线性映射$\sigma:V_1\to V_2$，即$ \sigma(v_1)\mapsto v_2,v_1\in V_1,v_2\in V_2$，满足两条性质：
   1. 保加法：$\sigma(e_1+e_2)=\sigma(e_1)+\sigma(e_2)$。也就是如果$e_1+e_2=e_3$，那么$\sigma(e_1)+\sigma(e_2)=\sigma(e_3)$。
   2. 保数乘：$\sigma(ke)=k\sigma(e)$。

2. $V_1,V_2$分别被称为输入空间和输出空间。线性性又称为满足叠加原理。
3. 如果$V_1=V_2=V$，则称$\sigma$称为$V$上的线性变换。
4. 若线性映射$\sigma$是可逆映射，则称$\sigma$是线性同构，$V_1,V_2$线性同构。

# 线性映射的矩阵表示

1. 从$F^n$到$F^m$之间的线性映射全体也构成一个线性空间。这个和域$F$上m行n列的矩阵的全体构成的这个线性空间是线性同构的。即任给一个m行n列的矩阵就能找到一个从$F^n$到$F^m$的线性映射与之对应，反之亦然。
2. 由矩阵$A$找线性映射$\sigma$，$\sigma(x)=Ax$其中$x\in F^n,A\in F^{m\times n}$。这里用到了矩阵的乘法，可以得出$y\in F^m$。
3. 由线性映射$\sigma$找矩阵$A$，先在$F^n$中选取一个标准基$e_1,e_2,\cdots,e_n$，然后分别将线性映射$\sigma$作用在这些基向量上，可以得到抽象矩阵$A'=[\sigma(e_1),\sigma(e_2),\cdots,\sigma(e_n)]$，可以证明对于任意$x\in F^n$，$\sigma(x)$都可以通过矩阵乘法$A'x$计算出。证明方法：将$x$在$F^n$的标准基上展开$x=e_1x_1+e_2x_2+\cdots+e_nx_n$，然后根据线性映射的保加法和保数乘的性质，可以证明。
4. 实际上任意有限维线性空间之间的线性映射都可以用矩阵表示。
5. 设任意两个线性空间$V,W$，分别为n维和m维。现各自选一个入口基$\varepsilon_1,\varepsilon_2,\cdots,\varepsilon_n$和出口基$\eta_1,\eta_2,\cdots,\eta_m$。其上存在一个线性映射$\sigma$，将$\varepsilon_1,\varepsilon_2,\cdots,\varepsilon_n$映射到$W$中，这些向量可以分别在基$\eta_1,\eta_2,\cdots,\eta_m$下展开，例如：$\sigma(\varepsilon_1)=[\eta_1,\eta_2,\cdots,\eta_m]\times\begin{bmatrix} a_{11}\\ a_{21}\\ \vdots \\ a_{m1}  \end{bmatrix}$，因此$\sigma(\varepsilon_1,\varepsilon_2,\cdots,\varepsilon_n)_{m\times n}=[\eta_1,\eta_2,\cdots,\eta_m]_{m\times m}\times\begin{bmatrix} a_{11} & \cdots a_{1n}\\ a_{21} & \cdots a_{2n}\\ \vdots \\ a_{m1} & \cdots a_{mn} \end{bmatrix}_{m\times n}$。
6. 综上，称矩阵$A=\begin{bmatrix} a_{11} & \cdots a_{1n}\\ a_{21} & \cdots a_{2n}\\ \vdots \\ a_{m1} & \cdots a_{mn} \end{bmatrix}$为映射$\sigma$在入口基$$\varepsilon_1,\varepsilon_2,\cdots,\varepsilon_n$$和出口基$\eta_1,\eta_2,\cdots,\eta_m$下的矩阵表示。该矩阵的第$j$列是第j个入口基向量的像在出口基下的坐标。线性变换的矩阵表示是方阵。
7. 用坐标计算线性映射：任意两个线性空间$V,W$，分别为n维和m维。现各自选一个入口基$\varepsilon_1,\varepsilon_2,\cdots,\varepsilon_n$和出口基$\eta_1,\eta_2,\cdots,\eta_m$。其上存在一个线性映射$\sigma$，其在这对基下的矩阵表示为$A$。则$\sigma(v)=[\eta_1,\eta_2,\cdots,\eta_m]Ax$，其中$v\in V,v=[\varepsilon_1,\varepsilon_2,\cdots,\varepsilon_n]x$，即$x$为$v$在入口基$\varepsilon_1,\varepsilon_2,\cdots,\varepsilon_n$下的坐标。
8. $F^n$中的元素可以走两条路线映射到$F^m$中：
   1. 可以先通过基$\varepsilon_1,\varepsilon_2,\cdots,\varepsilon_n$映射到V中，然后通过线性映射$\sigma$映射到$W$中，在通过基$\eta_1,\eta_2,\cdots,\eta_m$映射到$F^m$中。
   2. 也可以直接通过线性映射$\sigma$的在入口基$\varepsilon_1,\varepsilon_2,\cdots,\varepsilon_n$和出口基$\eta_1,\eta_2,\cdots,\eta_m$下的矩阵表示$A$来计算，即$Ax$。
9. <img src="矩阵分析.assets/image-20220225164950778.png" alt="image-20220225164950778" style="zoom:50%;" />
10. 微分算子就是对函数求导函数，将一个函数映射为另一个函数。
11. 微分算子的矩阵表示的例子，$R_4[x]\to R_3[x]$。入口基为$1,x,x^2,x^3$，出口基为$1,x,x^2$。其矩阵表示为$\begin{bmatrix}0&1&0&0\\0&0&2&0\\0&0&0&3 \end{bmatrix}$。例如$R_4[x]$中的一个向量$2x^3+5x$，在入口基下的坐标为$\begin{bmatrix} 0\\5\\0\\2\end{bmatrix}$。则该函数的导函数在出口基下的坐标为$\begin{bmatrix}0&1&0&0\\0&0&2&0\\0&0&0&3 \end{bmatrix}\times \begin{bmatrix} 0\\5\\0\\2\end{bmatrix}=\begin{bmatrix}5\\0\\6 \end{bmatrix}$，所以该函数的导函数为$5+6x^2$。这个是符合直接求导的结果的。
12. 几何空间绕定轴的旋转可以看作该线性空间的线性变换。一个轴可以定义一个正方向，右手定则来确定旋转角度的正负。
13. 对于线性变换，可以将入口基和出口基选择为同一个。 将旋转轴的正向定义为$e_3$，再和它垂直的面上按照右手法则找两个垂直的向量为$e_1$和$e_2$。分别将旋转变换作用域入口基，再将得到的向量在出口基下展开，可以得到该旋转变换的矩阵表示：$\begin{bmatrix} \cos\theta&-\sin\theta&0\\\sin\theta&\cos\theta&0\\0&0&1 \end{bmatrix}$。
14. 几何空间中关于某个面的镜像反射也是该线性空间的线性变换。一个面有两个法向，任选其中一个为$e_3$，然后在该面上按照右手法则选择两个相互垂直的向量为$e_1$和$e_2$，入口基和出口基相同。同上，可以得到镜像变换的矩阵表示为：$\begin{bmatrix} 1&0&0\\0&1&0\\0&0&-1 \end{bmatrix}$。

# 矩阵的等价

1. $A,B\in F^{m\times n}$是等价的$A\sim B$，如果存在可逆矩阵$P\in F^{n\times n},Q\in F^{m\times m}$，使得$AP=QB$。
2. 一个矩阵经过一系列的初等行列变换得到任意一个矩阵都与原矩阵等价。
3. 对一个矩阵进行一系列的初等行变换，等价于左乘一个可逆矩阵。对一个矩阵进行一系列的初等列变换，等价于右乘一个可逆矩阵。一次初等变换可以写成一个初等矩阵。
4. 可以将可逆矩阵$P,Q$分别看作n维，m维线性空间中的一个基。
5. 设线性映射$\sigma:F^n\to F^m$，在单位入口基$P=I_{n\times n}$和单位出口基$Q=I_{m\times m}$下的矩阵表示为矩阵$A$。那么$\sigma(P)=QAP=A$。
6. 矩阵等价的几何意义：矩阵A所代表的那个线性映射$\sigma$在任意入口基$P$和出口基$Q$下的矩阵表示就是$B$。
7. 可以通过选定特定的$P,Q$，使得B变得简单。这种$P,Q$是存在的，$B$的最简形式为：$\begin{bmatrix}I_r&0_{r,n-r}\\0_{m-r,r}&0_{m-r,n-r} \end{bmatrix}$，写成分块矩阵的形式。
8. 将$P,Q$拆分为列向量组，可以得到$Ap_1=q_1,\cdots,Ap_r=q_r,\cdots,Ap_{r+1}=0,\cdots,Ap_n=0$。可见$A$将$P$的前r个列向量组映射为$Q$的前r个列向量组，将后续的列向量组都映射为$F^m$中的0向量。
9. 也就是说$p_r,\cdots,p_n$构成矩阵$A$的核。
10. <img src="矩阵分析.assets/image-20220225194338772.png" alt="image-20220225194338772" style="zoom:50%;" />
11. 设线性映射$\sigma$在标准入口基和出口基下的矩阵表示为$A$，则$\sigma$将$F^n$中的向量$(x_1,x_2,\cdots,x_n)^T$映射为$F^m$中的向量$(y_1,y_2,\cdots,y_m)^T=Ax$。假设向量$(x_1,x_2,\cdots,x_n)^T$在新的入口基$P$下的坐标为$(x'_1,x'_2,\cdots,x'_n)^T$，$\sigma$将该向量映射到$F^m$中的像在新的出口基下的坐标$(y'_1,y'_2,\cdots,y'_m)^T=B(x'_1,x'_2,\cdots,x'_n)^T$。对于特殊的$B$，可以得到$y'_1=x'_1,\cdots,y'_r=x'_r,y'_{r+1}=0,\cdots,y'_{m}=0$。这样映射就解耦了。
12. 一个n入m处的静态线性系统可以解耦为r个单输入单输出的系统。

# 矩阵的相似

1. $A,B\in F^{n\times n}$，若存在可逆矩阵$P\in F^{n\times n}$，使得$AP=PB$，则称$A,B$相似。
2. 矩阵相似几何意义：与矩阵A对应的线性变换$\sigma$在入口基和出口基都为$P$下，其矩阵表示为$B$。
3. 任意方阵都存在一个相似最简型（尽可能多的零）。
4. 如果一个线性变换作用在某个子空间上的任意一个向量的结果还在该子空间内，那么就称该子空间为该线性变换的不变子空间。即对于$w\in W,W\subset F^n,A\in F^{n\times n}$，满足$Aw\in W$。
5. 显然$\{0\}$和$F^n$都是$A$的不变子空间。而$ker(A),im(A)$也是$A$的不变子空间。因为$A(ker(A))=0$，同时零向量在$ker(A)$中。
6. 不变子空间与相似三角化是等同的。$AP=PB$，$P=[P_1,P_2],B=\begin{bmatrix}B_{11}&B_{12}\\B_{21}&B_{22}  \end{bmatrix} $，且$A,B,P\in F^{n\times n}$，则有：
   1. $B_{21}=0$等价于$im(P_1)$为A的不变子空间，也就是$B$为分块上三角矩阵。
   2. $B_{12}=0$等价于$im(P_2)$为A的不变子空间，也就是$B$为分块下三角矩阵。
7. 由于分块矩阵的乘法规则，需要P的列分块模式$n_1:n_2$=B的行分块模式。又由于要分别计算$AP_1,AP_2$，所以需要$P$的列分块模式和$P$相同。因此$B_{11}$为$n_1$阶方阵，$B_{22}$为$n_2$阶方阵。证明技巧：根据$B_{21}=0$，可以推出$AP_1=P_1B_{11}$，这就表示$A$作用在$im(P_1)$的基上得到像也可以用$im(P_1)$的基表示，也就是说仍然在$im(P_1)$中，即$im(P_1)$是$A$的不变子空间。
8. $im(P_1)$为矩阵$P_1$的列向量组所张成的子空间，为$n_1$维，是$F^n$的子空间，$P_1$的列向量组就是这个子空间的一个基。
9. 给定一个矩阵$A\in F^{n\times n}$和他的一个不变子空间$W\in F^t$，如何将其相似三角化，也就是寻找$P$：可以先寻找$W$的一个基$\{w_1,\cdots,w_t\}$，然后将该基扩充成$F^n$的一个基$\{w_1,\cdots,w_t,u_1,\cdots,u_{n-t} \}$，两个列向量组分别为$P_1$和$P_2$，将他们拼成$P$即可。因为$AP_1=P_1\times *$，因此$A[P_1,P_2]=[P_1,P_2]\times \begin{bmatrix}*&*\\0&*  \end{bmatrix}$，所以可以将$A$分块三角化。
10. 将子空间的一个基扩充成原空间的一个基的步骤：
    1. 找出子空间的一个基$\alpha_1,\cdots,\alpha_s$和原空间的一个基$\beta_1,\cdots,\beta_n$。
    2. 依次尝试用子空间的基来表示原空间的一个基，可以肯定的是总会有不能表示的，例如$\beta_i$，此时将$\beta_i$加入到子空间的基中，然后再用新的向量组来尝试表示$\beta_i$后续的向量。最后总能将子空间的基扩充为全空间的一个基$\alpha_1,\cdots,\alpha_s,\beta_{r_1},\cdots,\beta_{r_{n-s}}$。因为如果一个线性无关的向量组能够线性表示一个基，则它能够线性表示该空间的所有向量，因此构成该空间的一个基，因此向量的个数为n。不过每一步尝试都要解线性方程组。
11. 另一种方法是对于$C^n$中适用的方法，可以将先将基拼成一个列向量组，然后将这个列向量组化成列最简型的，然后在后面添加标准正交向量即可。
12. 如过$B_{12},B_{21}$都为0，即$B$为分块对角矩阵。那么$im(P_1),im(P_2)$都是$A$的不变子空间。同理如果将矩阵$P$每一列都单独划分，那么$B$的每一个块都是一个数，则$im(P_i)$是$A$的不变子空间等价于$A$可以被$P$相似对角化。设$B=diag(\lambda_i)$于是由$AP_i=P_i\lambda_i$，这里的i不进行求和。
13. 特征向量就是一维不变子空间。
14. 方阵可以相似对角化的条件：存在n个线性无关的特征向量。因为将这n个线性无关的特征向量拼成一个矩阵就是所求的$P$矩阵。拼的顺序只会影响B对角线上值的位置，不过仍然是对角矩阵。
15. 并非所有矩阵都有n个线性无关的特征向量，也就是说不是所有矩阵都可以相似对角化。
15. 两个相似的矩阵特征值相同。

# 矩阵的分块计算

1. 一个矩阵可以在行和列方向同时分为多块，一般的矩阵就是分块到最细，例如：$\begin{bmatrix} 1&2&3\\3&2&1\end{bmatrix}$可以对行不分块或者说是按照2:0的方式分块，对列按照2:1的方式分块，结果为$\left[ \begin{array}{cc:c} 1&2&3\\3&2&1\end{array} \right]$，变成了一个1行2列的分块矩阵。
2. 对于$A+B$，要求$A$和$B$有相同的分块形式。
3. 对于矩阵的乘法$AB$，要求$A$的列分块模式和$B$的行分块模式相同，而$A$的列分块模式和$B$的行分块模式则无关，如何分分块矩阵都满足乘法的规则，结果也都是对的。
4. 矩阵之所以可以进行分块乘法是因为矩阵的乘法本质是行向量和列向量的乘法，对应数值相乘然后求和，利用加法的结合律可以将这些求和分成几个部分。
5. 例如$A\times B=\left[ \begin{array}{cc:c} 1&2&3\\3&2&1\end{array} \right]_{1\times 2} \times \left[ \begin{array}{cc}1&2\\3&3 \\ \hdashline2&1 \end{array} \right]_{2\times 1}$。这个分块矩阵的乘法计算步骤：
6. $\left[ \begin{array}{ccc}\left[ \begin{array}{ccc} 1&2\\3&2\end{array} \right]\times \left[ \begin{array}{ccc} 1&2\\3&3\end{array} \right] +\left[ \begin{array}{ccc} 3\\1\end{array} \right]\times \left[ \begin{array}{ccc} 2&1\end{array} \right]\end{array} \right]=\left[ \begin{array}{ccc}\left[ \begin{array}{ccc} 5&8\\9&12\end{array} \right]+ \left[ \begin{array}{ccc} 6&3\\2&1\end{array} \right]\end{array} \right]=\left[ \begin{array}{ccc} 13&11\\11&13\end{array} \right]$。结果和矩阵的直接乘法结果相同。
7. 分块矩阵的乘法满足分配律：$A\in F^{m\times n},B\in F^{n\times s}=(\beta_1,\beta_2,\cdots,\beta_s)$，B的行不分块，列细分，因此A的列也不分块，行可以是任意分块模式，不过这里也不进行分块，则 $AB=A(\beta_1,\beta_2,\cdots,\beta_s)=(A\beta_1,A\beta_2,\cdots,A\beta_s)$。同理，将A拆分为行向量组$\begin{bmatrix}\alpha_1 \\ \alpha_2 \\ \vdots \\ \alpha_m \end{bmatrix}$，则$AB=\begin{bmatrix}\alpha_1B \\ \alpha_2B \\ \vdots \\ \alpha_mB \end{bmatrix}$。
8. 单个数和行列向量都可以看作特殊的矩阵。
9. 分块矩阵的转置，先按照普通矩阵进行块外的转置，然后对各个块进行转置。例如：$A=\begin{bmatrix}A_{11}&A_{12}&A_{12}\\A_{21}&A_{22}&A_{23} \end{bmatrix}$，$A^T=\begin{bmatrix}A_{11}^T&A_{21}^T\\A_{12}^T&A_{22}^T\\A_{13}^T&A_{23}^T \end{bmatrix}$。
10. 对于稀疏矩阵，可以通过分块产生零矩阵，进而简化计算。
11. 分块三角矩阵的行列式：$\begin{vmatrix} A&0\\C&D \end{vmatrix}=\begin{vmatrix} A&B\\0&D \end{vmatrix}=det(A)\times det(D)$。
12. 分块对角矩阵：$A=\begin{bmatrix} A_1&0&\cdots&0\\0&A_2&\cdots&0\\\vdots&\vdots&\ddots&\vdots\\0&0&\cdots&A_n  \end{bmatrix}$，$A_i$和$A$都是方阵。其行列式为$det(A)=dete(A_1)\times\cdots\times det(A_n)$。其迹为$tr(A)=tr(A_1)+\cdots+tr(A_n)$。当且仅当$A_i$都是可逆的，$A$才是可逆的。

# $\lambda$矩阵

1. 普通的矩阵是以$F$中的数为元素，而$\lambda$矩阵（$(F[\lambda])^{m\times n}$）是以$F$上多项式为元素的矩阵。之所以叫$\lambda$矩阵，是因为将$\lambda$当作多项式的未定元。
2. 零次多项式也就是非零常值多项式。零多项式是恒为零的多项式，零多项式没有次数，规定次数为无穷更合理。
3. 可以将$\lambda$矩阵看成一个映射，$F\to F^{m\times n}$，将一个数$\lambda$映射为一个矩阵。
4. $\lambda$矩阵$A(\lambda)$可以写成以矩阵为系数的多项式：$A(\lambda)=A_0+A_1\lambda+A_2\lambda^2+\cdots+A_k\lambda^k$。其中$k$为$A(\lambda)$的次数，$A_0,\cdots,A_k$都是$m\times n$阶的。符号$\part (f(\lambda))$表示多项式$f(\lambda)$的次数。零多项式的次数无意义。
5. 定义矩阵的行列式只需要元素在一个环中即可，因为只用到了加减乘三种运算。多项式是一个环，因此可以为$A(\lambda)$定义行列式或子行列式。普通矩阵是定义在域上的，$\lambda$矩阵是定义在环上的。
6. $1/\lambda$不是多项式。多项式的次数只能取正整数。
7. $A(\lambda)$的秩为非零子式的最大阶数。这里的非零指的是非零多项式。
8. $A(\lambda)$的秩$\ge$给$\lambda$赋予任意值时$A$的秩，因为非零多项式可以有零点。
9. 单位模阵（幺模阵）：如果对于一个n阶$\lambda$矩阵$U(\lambda)$来说，存在另一个n阶$\lambda$矩阵$V(\lambda)$，满足$U(\lambda)V(\lambda)=V(\lambda)U(\lambda)=I_n$，那么就称它们互为对方的单位模阵。这个和$\lambda$的取值无关。
10. 也就是说只有逆矩阵仍然为$\lambda$矩阵时，才会将该矩阵称为单位模阵。
11. 任意$\lambda$矩阵$A$为单位模阵的充要条件是$|A|$是非零常值多项式，也就是$a_0\ne 0,a_1=a_2=\cdots=a_k=0$。即不存在$|A|$是$A*$中所有元素的公因式的情况。
12. 两个多项式相乘=常数，那么它们只能都是常值多项式。 因为多项式相乘次数会增加或不变。
17. 普通矩阵的初等行列变换：
    1. 某两行（列）互换位置。
    2. 某行（列）乘以非零常数。
    3. 某行（列）乘以一个数（可以是零）加到另一行（列）。
14. 对于$\lambda$矩阵来说，第1和3条都成立，只需将数变成多项式即可。而第2条中对于$\lambda$矩阵不一定成立，因为它的逆是除以一个非零多项式，这对于$\lambda$矩阵来说结果不一定是$\lambda$矩阵。
15. 初等行变换的效果可以通过左乘一个初等矩阵来实现，这个初等矩阵就是把相应的行变换作用在单位矩阵上。可以发现普通矩阵的第2条如果变成非零多项式，那么该初等矩阵不是单位模阵。
16. 由于$\lambda$矩阵的初等变换和原来数域上的矩阵不同，因此$\lambda$矩阵通过初等变换能达到最简形式也有所不同。
17. $\lambda$矩阵等价的等价定义和普通矩阵一样，$A(\lambda)$可以经过一系列的初等变换得到$B(\lambda)$，只不过是初等变换有限制。
18. 多项式的带余除法：$f(\lambda)=g(\lambda)q(\lambda)+\gamma(\lambda)$。其中$\part(\gamma(\lambda))<\part(g(\lambda))$。
25. （引理）用初等变换给$\lambda$矩阵的左上角降次：如果$A(\lambda)_{m\times n}$的左上角元素$a_{11}(\lambda)$是非零多项式，且$A(\lambda)$中至少有一个元素不能被$a_{11}(\lambda)$整除，则可以通过初等变换将$A(\lambda)$化为$B(\lambda)$，且$b_{11}(\lambda)\ne 0$，$\part(b_{11}(\lambda))<\part(a_{11}(\lambda))$。可以分为三种情况讨论：
    1. 第一行中存在一个不能被$a_{11}(\lambda)$整除的。将该元素$a_{1j}$除以$a_{11}(\lambda)$，得商记作$q(\lambda)$，余数$\gamma(\lambda)$，因此可以将第一列乘以$q(\lambda)$加到该列上去，那么$a_{1j}$变为$\gamma(\lambda)$，然后互换第1列和第$j$列，此时矩阵的左上角元素的次数小于原来的。
    2. 第一列中存在一个不能被$a_{11}(\lambda)$整除的。思路和上面的相同。
    3. 第一行和第一列都能被$a_{11}(\lambda)$整除的，假设$a_{ij}$不能被$a_{11}(\lambda)$整除，$i\ge1,j\ge1$。此时可以先将矩阵的第一行和第一列化简为0（因为整除的原因），化简后$a_{ij}$仍然不能被$a_{11}(\lambda)$整除。此时将第$i$行(第$j$列)加到第1行(第1列)去，就成为了情况1。
26. Smith标准型：任何一个$m\times n$阶$\lambda$矩阵都等价于一个分块矩阵，左上角为对角矩阵($\gamma$阶方阵)，另外三个都是零块。这个分块矩阵就成为该$\lambda$矩阵的Smith标准型。$A(\lambda)=\left[ \begin{array}{c:c}\begin{matrix}d_1(\lambda)&&\\&\ddots&\\&&d_\gamma(\lambda) \end{matrix} &0\\\hdashline 0&0 \end{array}\right]$。，其中$\gamma=\rank(A(\lambda))$，$d_i(\lambda)$为非零多项式，称为$A(\lambda)$的不变因子，且$d_i(\lambda)|d_{i+1}(\lambda)$。计算方法：
    1. 找出次数最低的多项式，通过换位移动到左上角。
    2. 此时$a_{11}(\lambda)$或者可以整除其他所有元素，或者不能（此时可以降次）。
    3. 最终$a_{11}(\lambda)$可以整除所有元素，然后通过行列变换，将第一行，第一列都变换为0。
    4. 然后对右下角的块重复之前的操作，对右下角块的初等变换不会影响到第一行和第一列的元素。
21. $f(\lambda)|g(\lambda)$表示前者可以整除后者，即$g(\lambda)=f(\lambda)\times q(\lambda)$。
22. 为了使得Smith标准型的样子统一，规定$d_i(\lambda)$都是首1多项式，即最高次项的系数为1。
23. $\lambda$矩阵的行列式因子：$A(\lambda)\in (F[\lambda])^{m\times n}$，$A(\lambda)$的所有$k$阶子式的最高公因式，称为$A(\lambda)$的$k$阶行列式因子，记作$D_k(\lambda)$。它的$k$阶子式一共有$C_m^k\times C_n^k$个，从m行和n列中分别去除k行和k列。
24. 初等变换不改变矩阵的所有阶行列式因子。$d_1(\lambda)=D_1(\lambda),d_i(\lambda)=D_i(\lambda)/D_{i-1}(\lambda)$。这也证明了Smith标准型式唯一的。$D_k(\lambda)=d_1(\lambda)\times\cdots\times d_k(\lambda)$。
31. 例子：$A(\lambda)=\begin{bmatrix}\lambda(\lambda+1)&0&0\\0&\lambda&0\\0&0&(\lambda+1)^2   \end{bmatrix}$。求它的Smith标准型。两种方法：
    1. 初等变换法：$A(\lambda)\to \begin{bmatrix}\lambda&0&(\lambda+1)^2\\0&\lambda(\lambda+1)&0\\0&0&(\lambda+1)^2   \end{bmatrix}\to \begin{bmatrix}\lambda&0&1\\0&\lambda(\lambda+1)&0\\0&0&(\lambda+1)^2   \end{bmatrix}\to \begin{bmatrix}1&0&\lambda\\0&\lambda(\lambda+1)&0\\(\lambda+1)^2&0&0   \end{bmatrix}$。一直变换下去，最终得到Smith标准型为$\begin{bmatrix}\lambda&0&0\\0&\lambda(\lambda+1)&0\\0&0&\lambda(\lambda+1)^2   \end{bmatrix}$。
    2. 通过行列式因子求不变因子：$D_1(\lambda)=1$。
26. 单位模阵的Smith标准型式单位矩阵。单位模阵可以写成有限个初等矩阵的乘积。
27. 数域$F$上$n$阶方阵$A$的特征矩阵$\lambda I-A$是多项式矩阵，$I$为单位矩阵。多项式矩阵$\lambda I-A$的行列式就是矩阵A的特征多项式。
28. 数域上矩阵$A,B$相似，即存在可逆矩阵$P$，使得$P^{-1}AP=B$  $\Leftrightarrow$  其特征矩阵$\lambda I-A,\lambda I-B$等价，即存在$U(\lambda),V(\lambda)$，使得$U(\lambda)(\lambda I-A)V(\lambda)=\lambda I-B$。
29. 已知$U(\lambda),V(\lambda)$，如何求$P$：
    1. 计算带余除法，$U(\lambda)=(\lambda I-B)Q(\lambda)+R(\lambda)$，有两种情况：①除尽，$R(\lambda)=0$，②除不尽，$\part (R(\lambda))<\part(\lambda I-B)=1$。则$R(\lambda)$应为一个常数矩阵（可以是零矩阵），记作$R$。
    2. 将上式带入$U(\lambda)(\lambda I-A)=\lambda I-BV^{-1}(\lambda)$，得到$R(\lambda I-A)=(\lambda I-B)[V^{-1}(\lambda)-Q(\lambda)(\lambda I-A)]$，等号右边的后一部分记作$S(\lambda)$，通过比较次数，可以知道$S(\lambda)$也是一个常数矩阵，记作$S$，且$R=S$。
    3. 计算带余除法，$U^{-1}(\lambda)=(\lambda I-A)\tilde{Q}(\lambda)+\tilde{R}(\lambda)$。由于$U(\lambda)$为单位模阵，因此计算$U(\lambda)U^{-1}(\lambda)=I$，带入上面的两个式子，可以得出$R\tilde{R}=I$，
    4. 因此$R$是可逆的，取$P=R^{-1}$即可。
30. 矩阵的相似变换需要左右的行列变换相对应，而等价变换则不用，自由度大大提高。这也是用多项式矩阵的观点来研究普通矩阵相似最简型的优点。
31. $\lambda$矩阵乘积的次数：设$A(\lambda)\in F[\lambda]^{n\times n}$，$B(\lambda),C(\lambda)\in F[\lambda]^{m\times n}$，$A(\lambda)B(\lambda)=C(\lambda)$，都不是零矩阵，如果$A(\lambda)$的最高次项的系数$A_r$可逆，则$\part(C(\lambda))=\part(A(\lambda))+\part(B(\lambda))$。之所以有这个限制条件，是因为两个非零矩阵的乘积可能是零矩阵。
32. $\lambda$矩阵的带余除法：若$n$阶方阵$A(\lambda)$的最高次项的系数$A_r$可逆，则对于非零矩阵$B(\lambda)\in (F[\lambda])^{m\times n}$，则存在唯一的$Q(\lambda),R(\lambda)$，使得$B(\lambda)=A(\lambda)Q(\lambda)+R(\lambda)$。商：Quotient，余数：Remainder。
33. 特征矩阵的Smith标准型，特征矩阵$\lambda I-A$的行列式(n阶子式)是$\lambda ^n$，不是零多项式，因此 $\lambda I-A$的秩为n，其Smith标准型应该占满主对角线。即$\begin{bmatrix}d_1(\lambda)&&\\&\ddots&\\&&d_\gamma(\lambda)  \end{bmatrix}$。
34. 同时$d_1(\lambda)\times\cdots\times d_n(\lambda)=D_n(\lambda)=|\lambda I-A|$，因为n阶行列式因子就是行列式本身。对前面的式子比较次数，可得$\part(d_1(\lambda))+\cdots+\part(d_n(\lambda))=n$。n个多项式次数的和为n，如果其中有一个多项式的次数为p，那么就有p-1个多项式的次数为0，也就是常数1。
35. 假设这$n$个不变因子中存在$p$个非常数的多项式，分别为$h_1(\lambda),\cdots,h_p(\lambda)$，次数分别为$n_1,\cdots,n^p$，那么就有$(n_1-1)+\cdots+(n_p-1)$个1。此时可以为Smith标准型进行变形，通过交换行列的方法将这些个1和它们对应的$n_i$次多项式放到一起，结果如下：$\left [\begin{array}{c:c:c}\begin{matrix}1&&\\&\ddots&\\&&h_1(\lambda)\end{matrix}&&\\ \hdashline &\ddots &\\ \hdashline&& \begin{matrix}1&&\\&\ddots&\\&&h_p(\lambda)\end{matrix} \end{array} \right]$。
36. 第一个子块是$n_i$阶的。重新变形后的矩阵已经不是Smith型了。
37. $\lambda$矩阵的初等因子：对$\lambda$矩阵的非常数不变因子$h_i(\lambda),i=1\cdots p$ 在$F[\lambda]$范围内进行质因式分解时出现的质因式的方幂称为$h_i(\lambda)$的初等因子。所有的$h_i(\lambda)$的初等因子的集合就称为$\lambda$矩阵的初等因子组（可以重复，不会剔除）。例如：$h_1(\lambda)=(x-2)^2(x+3)(x-5)^3,h_2(\lambda)=(x-2)(x-5)^3(x+8)$，该$\lambda$矩阵的初等因子组为：$\{ (x-2)^2,(x+3),(x-5)^3,(x-2),(x-5)^3,(x+8) \}$。
38. 初等因子组和不变因子相互唯一确定。由初等因子组求不变因子的例子：$\{\lambda,\lambda,\lambda^2,(\lambda+1)^2,(\lambda+1)^2\}$。由于最后一个不变因子必定除尽之前的所有不变因子，所以他必定包含所有的初等因子的形式，且幂次为最高，即$\lambda^2(\lambda+1)^2$，于是可以将刚才两个初等因子从初等因子组中划去，然后同理来找倒数第二个不变因子，即$\lambda(\lambda+1)^2$，同理倒数第三个不变因子为$\lambda$。
39. 矩阵$A,B$相似的各种刻画：
    1. 存在可逆矩阵$P$，使得$P^{-1}AP=B$。
    2. $\lambda I-A$与$\lambda I-B$等价。
    3. $\lambda I-A$与$\lambda I-B$有相同的Smith标准型。
    4. $\lambda I-A$与$\lambda I-B$有相同的不变因子。
    5. $\lambda I-A$与$\lambda I-B$由相同的行列式因子。
    6. $\lambda I-A$与$\lambda I-B$有相同的初等因子组。
42. 例如$A,A^T$相似，因为$\lambda I-A$和$\lambda I-A^T$具有相同的行列式因子。

# 复数域上矩阵的Jordan标准型

1. 复数域上的$n$次多项式一定有n个1次的质因式。
2. 对上述矩阵做进一步的变形，先将$h_i(\lambda)$做质因式分解为$h_i(\lambda)=(\lambda-c_1)^{r_1}\times \cdots \times (\lambda-c_k)^{r_k}$，包含$h_i(\lambda)$的子块可以做等价变换为：$\left [\begin{array}{c:c:c}\begin{matrix}1&&\\&\ddots&\\&&(\lambda-c_1)^{r_1}\end{matrix}&&\\ \hdashline &\ddots &\\ \hdashline&& \begin{matrix}1&&\\&\ddots&\\&&(\lambda-c_k)^{r_k}\end{matrix} \end{array} \right]$。
3. 然后将各个$h_i(\lambda)$的子块进行整合，得到：$\lambda I-A \sim  \begin{bmatrix}J_1(\lambda)&&\\&\ddots&\\&&J_q(\lambda)   \end{bmatrix}=J(\lambda)$。其中$J_i(\lambda)=\begin{bmatrix}1&&\\&\ddots&\\&&(\lambda-c_1)^{r_i}   \end{bmatrix}$。
4. 已知矩阵$A$，可以求出它的特征矩阵$\lambda I-A$的Smith型，然后可以将Smith型进一步做化简得到$J(\lambda)$，此时要寻找一个足够简单的矩阵$J$，使得它的特征矩阵$\lambda I-J$和$J(\lambda)$等价，也就是$J$和$A$相似。先对每一个子块$J_i(\lambda)$来解决问题，然后拼成整个矩阵即可。
5. Jordan块$J_i$为上三角矩阵，其特征矩阵$\lambda I-J_i$的Smith型就是$J_i(\lambda)$。$J_i=\begin{bmatrix} c_1 & 1 & & & \\ & c_1 & 1 & & \\ & & \ddots & \ddots & \\ & & & \ddots & 1 \\ & & & & c_1 \end{bmatrix}$，可以通过初等变换或计算行列式因子来证明。以一个4阶Jordan块为例，初等变换步骤：
   1. 初始为：$\begin{bmatrix}\lambda-c&-1&0&0\\0&\lambda-c&-1&0\\0&0&\lambda-c&-1\\0&0&0&\lambda-c    \end{bmatrix}$。先将第三行乘以$\lambda-c$加到第4行，然后将第二行乘以$\lambda-c$加到第三行，依次进行到底。
   2. 结果为：$\begin{bmatrix}\lambda-c&-1&0&0\\(\lambda-c)^2&0&-1&0\\0&(\lambda-c)^2&0&-1\\0&0&(\lambda-c)^2&0    \end{bmatrix}$。然后将第二列乘以$\lambda-c$加到第一列中，
   3. 结果为$\begin{bmatrix}0&-1&0&0\\(\lambda-c)^2&0&-1&0\\(\lambda-c)^3&(\lambda-c)^2&0&-1\\0&0&(\lambda-c)^2&0    \end{bmatrix}$。然后观察第一行和最后一列都是只有一个元素为-1，因此可以将该元素所在的行或列的所有元素都变成0。
   4. 结果为：$\begin{bmatrix}0&-1&0&0\\(\lambda-c)^2&0&-1&0\\0&0&0&-1\\0&0&(\lambda-c)^2&0    \end{bmatrix}$。然后将第三列乘以$(\lambda-c)^2$加到第一列中。
   5. 结果为：$\begin{bmatrix}0&-1&0&0\\0&0&-1&0\\0&0&0&-1\\(\lambda-c)^4&0&(\lambda-c)^2&0    \end{bmatrix}$，同理可以用第二行消去(4,3)的元素。
   6. 结果为：$\begin{bmatrix}0&-1&0&0\\0&0&-1&0\\0&0&0&-1\\(\lambda-c)^4&0&0&0    \end{bmatrix}$，此时可以对后三列乘以-1，然后交换列的顺序即可。
6. 行列式因子的思路：可以发现特征矩阵的$k$阶子式中存在一个特殊的子式，即选取去掉第一列和第一行，子矩阵就变成了下三角矩阵，再从中选取对角的$k$阶子式(即$(1,2)$到$(1+k,2+k)$)，行列式都是$\pm 1$，因此特征矩阵的$k,k=1\cdots n-1$阶的行列式因子都是1。而第$n_i$阶行列式因子即为$(\lambda-c)^{r_i}$。这个和Smith型的各阶行列式因子都相同。
7. 任意复数域上的矩阵都可以通过相似变换为它的Jordan标准型，后者是一个分块对角矩阵，每个块都是一个Jordan块，Jordan块是一个上三角矩阵，主对角线为特征值，次对角线为1。
8. 根据前面的分块矩阵可以相似化简为对角矩阵的记录呢，可以知道每个Jordan块所在的行列对应到$P$的列向量组构成的子空间是$A$的不变子空间。
9. $AP=PJ$，将$P$配合$J$做相应的分块，即$A[P_1,\cdots,P_q]=[P_1,\cdots,P_q] \begin{bmatrix}J_1&&\\&\ddots&\\&&J_q  \end{bmatrix}$。拆分开可得$AP_i=P_iJ_i$（$i$不求和），即$P_i$构成的子空间是$A$的不变子空间。
10. $C^n=im(P_1)\oplus\cdots\oplus im(P_q)$。子空间的直和。由于$P$是可逆的，即$P_i$之间都是线性无关的，因此构成直和。
11. 关于$P$的n阶矩阵方程$AP=PJ$可以解耦成$q$个低阶的矩阵方程。
12. 对于$AP_i=P_iJ_i$，，设$P_i=\{p_1,\cdots,p_{r_i}\}$可以展开得到：$Ap_1=p_1c_i,Ap_2=p_1+p_2c_2,\cdots,Ap_{r_i}=p_{r_{i-1}}+p_{r_i}c_i$。移项整理可得：$(A-c_iI)p_1=0,\cdots,(A-c_iI)p_{r_i}=p_{r_{i-1}}$。与$J_i$相应的$P$中的列向量组（$r_i$个基向量），构成第$i$个特征值$c_i$的一个广义特征向量链，其中$p_1$是真的特征向量。

# 代数基本知识

1. 质因式分解：任意一个多项式$f(\lambda)$可以写成如下形式：$q_1(\lambda)^{\gamma_1}\times q_2(\lambda)^{\gamma_2}\times \cdots \times q_s(\lambda)^{\gamma_s}$。
2. 质因式就是不能再分解多项式乘积的多项式。和数域内的质数类似。质因式和多项式的数域有关，例如实数域上的多项式$R[\lambda]$的质因式只有两种形式：$x-c$和$x^2+bx+c$其中$\Delta<0$。而$C[\lambda]$上的质因式只有一种形式$x-c$。
3. 代数基本定理：复数域上的n次多项式一定有n个复数根。由高斯证明。
4. 两个多项式存在最高公因式和最小公倍式。先对这两个多项式做质因式分解，然后互相不全不存在的项，不存在的项的次数为0，最后取每一项的较低的次数，连乘起来就是最大公因式，如果取较高的次数则是最小公倍式。例如：$(x-1)^2(x+3)(x+2)$和$(x-1)^3(x+3)^2(x-5)$补全后分别为：$(x-1)^2(x+3)(x+2)(x-5)^0$和$(x-1)^3(x+3)^2(x+2)^0(x-5)$。较小的次数依次为$2,1,0,0$，较高的次数依次为$3,2,1,1$。因此最高公因式为$(x-1)^2(x+3)$，最小公倍式为$(x-1)^3(x+3)^2(x+2)(x-5)$。
5. 辗转相除法（欧几里得算法），求两个整数$a,b$的最大公约数$(a,b)$：$(a,b) = (b,a\mod b)$。一直计算下去，总会出现如下情况$(a,b)=(m,n)=(n,0)$，其中$m=np$，则认为$n=(a,b)$。例如$(36,15)=(15,6)=(6,3)=(3,0)=3$。
6. $a\mod b=c$ 表示整数$a$除以整数$b$的余数为$c$。
7. 辗转相除法在大数计算中存在一个缺点，就是需要试商来求余数。
8. 将辗转相除的过程带回去，可以发现，两个多项式的最大公约式是这两个多项式的线性组合。
9. 矩阵的行列式的定义：所有取自不同行不同列的元素的乘积的代数和（n个数相乘，），一共有$n!$项，每一项都是n个数相乘，然后乘以一个正负号。这个正负号的计算步骤：
   1. 将这些元素按照行的顺序从小到大排列为$a_{1j_1},a_{2j_2},\cdots,a_{nj_n}$。
   2. 然后计算$j_1,j_2,\cdots,j_n$的逆序数$\tau(j_1,j_2,\cdots,j_n)$。
   3. 该正符号为$(-1)^{\tau(j_1,j_2,\cdots,j_n)}$。
10. 在行列式$A$中划去$a_{ij}$所在的行和列，其他元素按照原来的顺序排列，得到一个的$n-1$阶的行列式$M_{ij}$，称为元素$a_{ij}$的余子式，$A_{ij}=(-1)^{i+j}M_{ij}$称为$a_{ij}$的代数余子式。
11. 任取不在同一行同一列的n个元素（一般为同一行或同一列的n个元素），将他们和他们的代数余子式相乘，求和即可得到行列式$A$的值。这是通过降阶的方法来求行列式的值，将一个n阶行列式的计算变为n个n-1阶行列式的计算。
12. 矩阵$A$的伴随矩阵$A^*$：将$a_{ij}$替换为它的代数余子式$A_{ij}$，然后再转置即可。
13. 矩阵的逆矩阵计算方法：$A^{-1}=\frac{A^*}{|A|}$。对于$\lambda$矩阵，行列式是多项式，伴随矩阵是$\lambda$矩阵，但是二者的除法就不一定是$\lambda$矩阵。

# 内积

1. 定义内积是为了将一般几何空间中的长度，夹角对应到线性空间上。
2. 内积是一个映射：$V$是$R$上的一个线性空间，$\tau:V\times V\to R$。$\tau(v_1,v_2)$也可以写作$<v_1,v_2>$。如果$\tau$满足以下三个条件：
   1. 对称性，$<v_1,v_2>=<v_2,v_1>$。
   2. 对第二个变元的线性性，$<v_1,v_2k+v_3l>=<v_1,v_2>k+<v_1,v_3>l$。也就是说$<v_1,\cdot>$是线性映射。
   3. 正定性，$<v,v>\quad \ge0$，当且仅当$v=0$时取等号。
3. 内积空间：定义了内积的线性空间。这里说的内积仅限于实数域上，复数域上的线性空间的内积和上面的不同。复数的内积要满足共轭对称性。
4. 有限维的内积空间就是欧几里得空间。
5. 由对称性和对第二个变元的线性性，可得对第一个变元也是现行的，即$<\cdot,v>$也是一个线性映射。即内积具有双线性。因此如果已知两个向量组之间的任意两个向量的内积，即可获得这两个向量组各自生成的向量之间的内积。
6. 由对称性和对第二个变元的线性性，可得零向量和任意向量的内积都是0，$<v,0>=<v,u+(-u)>=<v,u>+<v,-u>=<v,u>-<v,u>=0$。同理也可得$<0,v>=0$。这个结论对于复内积空间也是成立的。因为0的共轭复数仍然是0。
7. $R^n$上的标准内积：$R^n\times R^n\to R$，$<x,y> \mapsto x^Ty$。非标准内积的例子：对于$R^2$上两个向量$x=(x_1,x_2)$和$y=(y_1,y_2)$可以定义$<x,y>=x_1y_1+\frac{1}{2}x_1y_2+\frac{1}{2}x_2y_1+x_2y_2$。可以证明它满足内积的三个条件，$<x,y>=[x_1,x_2]\begin{bmatrix}1&\frac{1}{2}\\\frac{1}{2}&1 \end{bmatrix}\begin{bmatrix} y_1\\y_2  \end{bmatrix}$。这是一个正定的二次型。
8. 每一个正定二次型都对应一个内积。
9. 函数空间的内积：例如$C([a,b],R^n)$是定义在$[a,b]$上，取值在$R^n$中的所有连续函数构成的函数空间。一元向量值函数。当$n=1$时，可以简写为$C[a,b]$。$<f(t),g(t)>=\int_a^bf^T(t)g^T(t)\text{d}t$。被积函数是关于$t$的一元标量函数。
10. 标量函数是和向量函数对应的，不能称为单值函数，因为函数都是单值的。
9. $V$是定义在$C$上的线性空间，其上的内积需要满足：
   1. 共轭对称性：$<v_1,v_2>=\overline{<v_2,v_1>}$。
   2. 对第二个变元线性性。
   3. 正定性。复线性空间的内积是复数。正定性要求自己和自己的内积是实数且>0。因为复数是无法比较大小的。
12. 有限维的复内积空间就是酉空间。
13. 根据共轭对称性和对第二个变元的线性性，可得对第一个变元是共轭线性的，也成为半线性。$<v_1k+v_2l,u>=\overline{k}<v_1,u>+\overline{l}<v_2,u>$。证明会用到共轭的和等于和的共轭，共轭的乘积等于乘积的共轭。
14. 实际上复内积的第二条也可定义为对第一个变元是线性的，不过此时$C^n$上的标准内积就得变成$<x,y>=x^T\overline{y}$。这样的形式被认为是丑的。
15. $C^n$上的标准内积：$<x,y>=\overline{x}^Ty=\overline{x^T}y$。$x$向量先共轭，再转置。这里先转置再共轭是相同的。
16. 对于复数$c=a+bi$来说，$c\overline{c}=|c|^2=a^2+b^2$。

# Gram矩阵

1. 线性组合的内积的矩阵表示：$<\Sigma_{i=1}^s\alpha_ik_i,\Sigma_{i=1}^t\beta_il_i>=[\overline{k_1},\cdots,\overline{k_s}]\begin{bmatrix}&& \\& <\alpha_i,\beta_j> &\\&& \end{bmatrix}_{s\times t} \begin{bmatrix} l_1\\ \vdots\\l_t \end{bmatrix}$。
2. 向量组的Gram矩阵，设$\beta_1,\cdots,\beta_s$是（实或复）内积空间的一个向量组，这个向量组的Gram矩阵定义为：$G(\beta_1,\cdots,\beta_s)=\begin{bmatrix}&& \\& <\beta_i,\beta_j> &\\&& \end{bmatrix}_{s\times s}$。
3. 基向量组（坐标系）的Gram矩阵称为这个基的度量矩阵。也就是说内积由度量矩阵唯一决定。
4. Gram矩阵的性质：
   1. Hermite性，$\overline{G}^T=G$。矩阵的共轭就是每个元素的共轭。也成为复对称性。
   2. 非负定性（半正定），即在复数$z\ne0$时，复二次型$\overline{z}^TGz\ge0$。因为$\overline{z}^TGz=<\beta_1z_1+\cdots+\beta_sz_s,\beta_1z_1+\cdots+\beta_sz_s>$，根据内积的正定性，可以得出该二次型是半正定的。这里需要注意，虽然$z\ne0$，但是不能保证$\beta_1z_1+\cdots+\beta_sz_s\ne0$，因为没有$\{\beta_1,\cdots,\beta_s\}$不一定是线性无关的。
   3. $G$正定$\Leftrightarrow$$\{\beta_1,\cdots,\beta_s\}$线性无关。
   4. $\rank(G)=\rank(\{\beta_1,\cdots,\beta_s \})$ ，给出了判断内积空间中抽象向量组线性相关性的具体办法。
5. $|A|$表示矩阵$A$的行列式，$\norm{a}$表示向量$a$的模。
6. 矩阵$A$的列向量组的Gram矩阵为$\overline{A}^TA$。
7. 矩阵$A$的列向量组和另一个向量$\beta$的Gram矩阵为$\overline{A}^T\beta$。
8. 几何空间作为内积空间，几何空间的内积定义为$<\alpha,\beta>=\norm{\alpha}\norm{\beta}\cos\theta$，向量之间的夹角取值范围为$[0,\pi]$。
9. 对于两个向量$\alpha,\beta$，它们的Gram矩阵的行列式为：$|G(\alpha,\beta)|=\norm{\alpha}^2\norm{\beta}^2\sin^2\theta$。也就是向量构成的平行四边形的面积的平方。对于向量组$\alpha,\beta,\cdots$，将$\sqrt{G(\alpha,\beta,\cdots)}$称为向量组张成的平行多面体体积。
10. $C^n$中的Gram矩阵：向量组$\beta_1,\cdots,\beta_s$，可以拼成一个矩阵$B=[\beta_1,\cdots,\beta_s]$，则$G(\beta_1,\cdots,\beta_s)=\overline{B}^TB$。
11. 根据内积来定义向量的长度和距离：$\norm{\alpha}=\sqrt{<\alpha,\alpha>}$。距离是定义在两个向量之间的：$d(\alpha,\beta)=\norm{\alpha-\beta}$。这种方式规定的长度和距离符合一般几何空间的意义。
    1. 正性：对于任意的$\alpha$，$\norm{\alpha}\ge0$，当且仅当$\alpha=0$时，取等号。
    2. 正齐性：$\norm{\alpha k}=|k|\norm{\alpha}$，$k$是任意复数。$|k|$对于复数来说表示取模长，对于实数来说表示取绝对值。$\norm{\alpha k}=\sqrt{<\alpha k,\alpha k>}=\sqrt{\overline{k}<\alpha,\alpha>k}=\sqrt{|k|^2\norm{\alpha}^2}=|k|\norm{\alpha}$。
    3. 三角不等式：$\norm{\alpha\pm\beta}\le\norm{\alpha}+\norm{\beta}$。三个向量长度之间的关系。
    4. 柯西-施瓦茨不等式：$|<\alpha,\beta>|\le \norm{\alpha}\norm{\beta}$。不等式左边是对内积的结果取模。右边是向量长度的乘积。等号成立的充要条件：$\alpha,\beta$ 线性相关。
    5. 平行四边形公式：$\norm{\alpha+\beta}^2+\norm{\alpha-\beta}^2=2(\norm{\alpha}^2+\norm{\beta}^2)$。
12. 距离的三角不等式，三个向量$\alpha,\beta,\gamma$：$d(\alpha,\beta)\le d(\alpha,\gamma)+d(\gamma,\beta)$。三个向量可以产生三个新的向量$\alpha-\beta,\alpha-\gamma,\gamma-\beta$。其中$\alpha-\beta=(\alpha-\gamma)+(\gamma-\beta)$。对他们使用向量长度的三角不等式。
13. 可以定义实内积空间中向量的夹角和复内积空间中正交（都是从几何空间中借鉴来的）：
    1. $\angle_\alpha^\beta$定义为$\arccos{\frac{<\alpha,\beta>}{\norm{\alpha}\norm{\beta}}}$。在实内积空间中，$<\alpha,\beta>$为实数，且由柯西-施瓦茨不等式可知反余弦内的自变量是在$[-1,1]$的，因此可以求反余弦。结果应该在$[0,\pi]$中取值。一个向量和零向量的夹角没有意义。复内积空间没有夹角概念。
    2. 非零向量$\alpha \perp \beta:=<\alpha,\beta>=0$。在实内积空间中，正交就等于夹角90°。
14. 几何空间中，夹角和长度是比内积更具体，更早的，内积是认为造出来的，而在抽象空间中，夹角和长度是由内积生成的。
15. 当$\alpha\perp\beta$时，有勾股定理：$\norm{\alpha\pm\beta}^2=\norm{\alpha}^2+\norm{\beta}^2$。但是后者并不能推出前者，因为后者可以推出$<\alpha,\beta>+<\beta,\alpha>=0$，即$Re(<\alpha,\beta>)=0$。并不能证明$\alpha \perp\beta$。

# 投影定理

1. 投影问题：$V$是定义在$C$上的内积空间。$\beta\in V$，$W$是$V$的有限维子空间。求$W$中的一个元素$\alpha$，使得$d(\beta,\alpha)$取最小值。也就是说要在$W$中找一个和$\beta$距离最近的向量$\alpha$。这是个最优逼近问题。最小二乘法，模式识别等技术中都用到了该方法。这个$\alpha$就是$\beta$在子空间$W$中的投影。最优解是存在且唯一的。
   1. 设$W$为$s$维的子空间，因此可以找到一个基$\beta_1,\cdots,\beta_s$。则$\alpha$可以表示为$\Sigma_{i=1}^s\beta_ik_i$。
   2. 则$d(\beta,\alpha)=d(\beta,\Sigma_{i=1}^s\beta_ik_i)$，可以看成是一个s元的标量函数。求偏导即可。
2. 另一种借助于几何的思路是：当$\beta-\alpha\perp W$，$\alpha$为所求。可以由勾股定理来证明。$\beta-\alpha\perp \alpha-w$，则有$\norm{\beta-\alpha}^2+\norm{\alpha-w}^2=\norm{\beta-w}^2$，则有$d(\beta-\alpha)\le d(\beta-w)$。
3. 向量垂直于子空间，则是垂直于子空间的任意一个向量，充要条件就是向量垂直于子空间的一个基即可。因此$<\beta-\Sigma_{i=1}^s\beta_ik_i,\beta_i>=0$。利用内积的线性性，可得$G(\{\beta_i\})[k_1,\cdots,k_s]^T=G(\{\beta_i\},\beta)$，这个关于$[k_1,\cdots,k_s]^T$线性方程组被称为最优问题的正规方程。 
4. 可以解得$[k_1,\cdots,k_s]^T=G(\{\beta_i\})^{-1}G(\{\beta_i\},\beta)_{s\times 1}$，后面的这个Gram矩阵是s行1列的。由于$\beta_i$是基，因此Gram矩阵是正定的，可逆。
5. $\alpha=\arg \min \{d(\beta,w)|w\in W\}$，$\arg\min$ 表示$\alpha$为使得min成立的参数。$\alpha$为最小值点。
6. 当$W$是一维子空间时，可以先将$\beta_1$单位化为$\tilde{\beta}=\frac{\beta_1}{\norm{\beta_1}}$。然后$\beta$在$\tilde{\beta}$上的投影长度就是$<\beta,\tilde{\beta}>$，投影向量就是$\tilde{\beta}<\beta,\tilde{\beta}>$。
7. 投影定理：任意向量向子空间$im(A)$中的投影，其中$A\in C^{n\times s}$是一个列满秩矩阵，即$A$的列向量组构成$im(A)$的一个基。由于$A$是列满秩的，因此$A$的列向量组的Gram矩阵$\overline{A}^TA$是可逆的。由投影定理，$\beta$在矩阵$A$的列向量组张成的子空间中的投影为$P_A(\beta)=AG(A)^{-1}G(A,\beta)=A(\overline{A}^TA)^{-1}\overline{A}^T\beta$。则投影矩阵$P_A=A(\overline{A}^TA)^{-1}\overline{A}^T$。
   1. $P_A$是Hermite的。
   2. $P_A$是幂等的，$P_A^2=PA$，即多次投影等价于一次投影。
   3. $\rank(P_A)=\rank(A)$。
8. 观测数据的最小二乘拟合：观测数据为$N$个有序对$(x_0,y_0),\cdots,(x_{N-1},y_{N-1})$。用来拟合的函数取自某一个函数子空间内，或曲线族内，而不是任意函数。例如拟合的函数在$k-1$次多项式$F_k[x]$中，$f(a_o,\cdots,a_{k-1};x)=\Sigma_{i=0}^{k-1}a_ix^k$。拟合指标是：$\arg\min \{\Sigma_{i=1}^N|f(x_i)-y_i|^2\}$，可以简化：$\arg\min\{\norm{f(x_i)-y_i}^2 \}=\arg\min\{\norm{f(x_i)-y_i}\}$。$N$个数的平方和，可以看作这个$N$个数构成的向量的长度。
9. 从投影的角度来看，$F_k[x]$是子空间，该子空间的一个基可以是$1,x,\cdots,x^{k-1}$。全空间可以认为是函数空间，毕竟真实的$(x,y)$关系可能是任意形式的函数。依次将$k$个基函数在自变量$x_i,\cdots,x_N$上进行采样，可以得到$k$个$N$维列向量$\beta_i=[x_0^i,\cdots,x_{N-1}^i]^T,i=0,\cdots k-1$。现在是要寻找$\min \{\norm{\beta-\Sigma_{i=0}^{k-1}\beta_ia_i} \}$，即在这$k$个$N$维列向量张成的子空间内寻找一个向量和$\beta$的距离最近。这个向量就是$\beta$在该空间中的投影。然后根据投影定理计算即可。当$k\le N$时这$k$个$N$维列向量可以看作是从范德蒙矩阵（第一行都是1）中抽取的$k$行。由于范德蒙矩阵是可逆的，因此此时这$k$个$N$维列向量构成的矩阵$A$是列满秩的。因此$\overline{A}^TA$可逆。当$k>N$时，。

# 标准正交基

1. 标准正交基：$V$时$C$上的内积空间，$\alpha_1,\cdots,\alpha_s$是$V$的一个标准正交基，应满足：
   1. 标准性：$\norm{\alpha_i}=1$。
   2. 正交性：$\alpha_i\perp\alpha_j \quad\forall i\ne j$。
2. 标准正交基的Gram矩阵为单位矩阵，这也是标准正交基的好处。
3. $L^2([0,2\pi])$，定义在$[0,2\pi]$上的平方可积的所有函数。也就是说$\int_0^{2\pi}|f(t)|^2\text{d}t<+\infty$，积分有界。它的一个子空间可以是定义在$[0.2\pi]$上的连续函数。因为定义在闭区间的连续函数必定有界，必定平方可积。
4. 傅里叶三角分解：$\{\frac{1}{\sqrt{2\pi}},\frac{1}{\sqrt{\pi}}\sin nx, \frac{1}{\sqrt{\pi}}\cos nx  \},n=1,2,\cdots$。可以验证这个向量组是标准正交基。
5. $L^2([0,2\pi])$中的任意一个函数（向量）都可以在这个基下分解：$f(x)\sim c_0\frac{1}{\sqrt{2\pi}}+\Sigma_{i=1}^{\infty}a_i\frac{1}{\sqrt{\pi}}\sin nx+\Sigma_{i=1}^{\infty}b_i\frac{1}{\sqrt{\pi}}\cos nx$。利用这个基是标准正交的，就可以轻松地求出各个系数，要求哪个系数，就将求$f(x)$和该系数对应的基的内积，由于正交性等号右边只会剩下一项，系数乘以基和它自己的内积，由于标准性，等号右边就是那个系数。
6. $n$维内积空间中标准正交基是一定存在的。任意一个基$\alpha_1,\cdots,\alpha_n$可以通过Schmidt正交化方法来变成正交基，然后再标准化即可。
   1. $\beta_1=\alpha_1$
   2. $\beta_2=\alpha_2-\boxdot\beta_1$
   3. $\beta_3=\alpha_3-\boxdot\beta_1-\boxdot\beta_2$
   4. $\cdots$
   5. $\beta_n=\alpha_n-\boxdot\beta_1-\cdots-\boxdot\beta_{n-1}$
7. 上面的每一个$\boxdot$都可以用$\beta_i$之间的正交性来求解。例如在第二式左右两侧和$\beta_1$做内积。可得$<\beta_2,\beta_1>=<\alpha_2,\beta_1>-\boxdot<\beta_1,\beta_1>$，等号左边为0。
8. 因此定义在$F$上的$n$维内积空间中，抽象向量$\alpha,\beta$的内积$<\alpha,\beta>$等于它们在标准正交基下的坐标向量$x,y$，在$F^n$中标准内积$\overline{x}^Ty$。
9. 标准正交基的存在保证了任意一个有限维的内积空间同构于标准内积空间。
10. 利用Schmidt正交化的方法可以将$1,x,x^2,\cdots,x^n$正交化，得到勒让德正交多项式。在数值积分中用到。

# 酉矩阵与QR分解

1. 酉矩阵就是复正交矩阵。，$\overline{A}^TA=I_n$。酉矩阵的列向量组构成标准酉空间中的标准正交基。
2. 可逆矩阵的QR分解，也称为正交三角分解：
   1. 任意列满秩的$n$阶复矩阵$A=[a_1,\cdots,a_n]$，根据Schmidt正交化的步骤，可以根据$\{a_1,\cdots,a_n\}$构造出正交基$\{b_1,\cdots,b_n\}$，可得$A=B\begin{bmatrix} 1&&*\\   &\ddots&\\0&&1    \end{bmatrix}$。
   2. 然后将$\{b_1,\cdots,b_n\}$标准化为$\tilde{B}=\{\tilde{b_1},\cdots,\tilde{b_n} \}$，可得$B=\tilde{B}\begin{bmatrix} \norm{b_1}&&\\&\ddots&\\&&\norm{b_n}   \end{bmatrix}$。
   3. 因此可以得到$A=\tilde{B}\begin{bmatrix} \norm{b_1}&&*\\   &\ddots&\\0&&\norm{b_n}    \end{bmatrix}$。也就是将一个可逆矩阵分解为了一个酉矩阵和上三角矩阵的乘积，且这个上三角矩阵的对角线都是正实数。
3. QR分解是唯一的。由于上三角矩阵也被称为右三角矩阵，因此QR中的R表示的是上三角。
4. 酉矩阵作为线性变换是保内积的。即$<Ux,Uy>=<x,y>$。因此也是保长度的$\norm{Ux}=\norm{x}$。
5. 实际上由长度也可以定义内积，例如假设$<x,y>=Re <x,y>+iIm<x,y>$，其中实部$Re<x,y>=\{\norm{x+y}^2-\norm{x}^2-\norm{y}^2\}/2$，虚部$Im<x,y>=-Re<x,iy>=\{-\norm{x+iy}^2+\norm{x}^2+\norm{y}^2\}/2$。因此由保长度也可以推出保内积。
6. 酉矩阵的例子：
   1. 三维空间绕定轴旋转的矩阵表示：$\begin{bmatrix} \cos\theta&-\sin\theta&0\\\sin\theta&\cos\theta&0\\0&0&1 \end{bmatrix}$。绕定轴正向按照右手定则旋转角度为$\theta$。空间内的所有向量都会跟着旋转。
   2. 三维空间镜面反射变换的矩阵表示：$\begin{bmatrix} 1&0&0\\0&1&0\\0&0&-1 \end{bmatrix}$。镜面法向为$e_3$。
7. 以上两个矩阵都是线性变换在特定基下的矩阵表示。
8. 酉矩阵的特征值的模均为1。
9. 任意$n$阶矩阵$A$，可以用一个可逆矩阵$P$来相似变换为它的Jordan标准型。$AP=PJ$，这表示线性变换$A$在一般基$P$下的矩阵表示为$J$，如果限制这个$P$只能是酉矩阵，那么矩阵$A$可以最简化为它的Schur标准型。
10. Schur定理：对于任意$n$阶复矩阵$A$，存在酉矩阵$U$，使得$U^{-1}AU$为上三角矩阵。酉相似变换。可以用Jordan标准型来证明，$AP=PJ$，而对可逆矩阵$P$可以做QR分解，$P=UR$，带入前式得：$AUR=URJ$，等号两端左乘$U^{-1}$，再右乘$R^{-1}$可得$U^{-1}AU=RJR^{-1}$。上三角矩阵的你还是上三角矩阵，两个上三角矩阵的乘积还是上三角矩阵。Jordan标准型是分块对角矩阵，也是上三角矩阵。
11. 方阵$A$通过酉相似变换得到的Schur标准型为对角矩阵的充要条件为$\overline{A}^TA=A\overline{A}^T$。即$\overline{A}^T$和$A$是可交换的。这样的矩阵称为正规矩阵。

# Hermite矩阵

1. Hermite（复对称）矩阵：$\overline{A}^T=A$。Hermite是正规矩阵中典型的一类。对于Hermite矩阵来说，它的特征值都是实数。
2. 根据Hermite矩阵对应的二次型的正负，可以将Hermite矩阵分为正定，非负定，非正定，负定，不定。一般说正定矩阵指的都是Hermite正定。
   1. 矩阵正定$\Leftrightarrow$所有特征值都是正的。
   2. 矩阵非负定$\Leftrightarrow$所有特征值都是非负的。

3. 非负定矩阵$A$最大特征值$\lambda_{\max}$的极值刻画：$\lambda_{\max}(A)=\max \frac{\overline{x}^TAx}{\overline{x}^Tx}$，其中$x\ne0$。将$x$单位化后也可以是$\lambda_{\max}(A)=\max \overline{x}^TAx$，其中$\norm{x}=1$。这个定理提供了一种求非负定矩阵最大特征值的简化方法。最小特征值$\lambda_{\min}$也能由此刻画，即$\min \overline{x}^TAx$，其中$\norm{x}=1$。
4. $\max \frac{\overline{x}^TAx}{\overline{x}^Tx}$也被称为一个矩阵的瑞利商。

# 奇异值分解

1. 奇异值分解：两个$m\times n$矩阵$A,B$等价，意味着存在可逆矩阵$P,Q$，使得$AP=QB$，$B$是分块矩阵，左上角为$I_r$，其中$r=\rank(A)$，另外三个块都是零块。上面是不限制$P,Q$的形式，如果限制$P,Q$只能是酉矩阵，则$B$最简能化为$\left[ \begin{array}{c:c}\begin{matrix} \sigma_1&&\\&\ddots&\\&&\sigma_r  \end{matrix}&0\\ \hdashline0&0  \end{array}\right]$。即$AU=VB$。$\sigma_1\ge\sigma_2\ge\cdots\ge\sigma_r\gt0$。都是正实数，一般按照大小排列。$r=\rank(A)$，$\sigma_i=\sqrt{\lambda_i(\overline{A}^TA)}$，称为$A$的奇异值。也将$\begin{bmatrix} \sigma_1&&\\&\ddots&\\&&\sigma_r  \end{bmatrix}$记作$\Sigma$。证明思路下面寻找对应的$U,V$：
   1. 由于$\overline{A}^TA$是$A$的列向量组的Gram矩阵，是一个Hermite矩阵。由Gram矩阵的性质，可得：$\rank(\overline{A}^TA)=\rank(A)=r$。由于$\overline{A}^TA$是Hermite矩阵，因此可以将他酉相似化为对角矩阵，即$\overline{U}^T\overline{A}^TAU=\Lambda=\left[ \begin{array}{c:c}\begin{matrix} \lambda_1&&\\&\ddots&\\&&\lambda_r  \end{matrix}&0\\ \hdashline0&0  \end{array}\right]$。$\lambda_i$是$\overline{A}^TA$的特征值。
   2. 令$H=AU$，$H$是$m\times n$的，则$\overline{H}^TH=\left[ \begin{array}{c:c}\begin{matrix} \lambda_1&&\\&\ddots&\\&&\lambda_r  \end{matrix}&0\\ \hdashline0&0  \end{array}\right]$。将$H$按照$\Lambda$一样做列分块，$H=[h_1,\cdots,h_r,h_{r+1},\cdots,h_n]=[H_1,H_2]$。则$\begin{bmatrix} \overline{H_1}^TH_1&\overline{H_1}^TH_2\\\overline{H_2}^TH_1 &\overline{H_2}^TH_2  \end{bmatrix}=\Lambda$。则$H_2=0$，$H_1$的列向量组$\{h_1,\cdots,h_r\}$为正交向量组，且$\lambda_i=\norm{h_i}^2$。
   3. 然后将$\{h_1,\cdots,h_r\}$化为标准的。$\tilde{H_1}=\{\tilde{h_1}.\cdots,\tilde{h_r}\}=\{h_1/\norm{h_1},\cdots,h_r/\norm{h_r} \}=\{h_1/\sqrt{\lambda_1},\cdots,h_r/\sqrt{\lambda_r}  \}$。将$\{\tilde{h_1}.\cdots,\tilde{h_r}\}$扩充成$C^m$的一个标准正交基$\{\tilde{h_1}.\cdots,\tilde{h_r},\beta_{r+1},\cdots,\beta_m\}$，这个基拼成的矩阵记作$V$，为酉矩阵。$AU=H=\{h_1,\cdots,h_r,0,\cdots,0\}=\{\tilde{h_1}.\cdots,\tilde{h_r},\beta_{r+1},\cdots,\beta_m\}\left[ \begin{array}{c:c}\begin{matrix} \sqrt{\lambda_1}&&\\&\ddots&\\&&\sqrt{\lambda_r}  \end{matrix}&0\\ \hdashline0&0  \end{array}\right]=VB$
2. 奇异分解的作用：$A$可以看作是$C^n$到$C^m$的线性映射，存在$AU=VB,B=\left[ \begin{array}{c:c}\begin{matrix} \sigma_1&&\\&\ddots&\\&&\sigma_r  \end{matrix}&0\\ \hdashline0&0  \end{array}\right]$，$x\mapsto y=Ax$。在$C^n$中选择一个标准正交基，即$U$的列向量组，则$x=U\tilde{x}$，在$C^m$中选择一个标准正交基，即$V$的列向量组，则$y=V\tilde{y}$。因此可得$V\tilde{y}=AU\tilde{x}$，$\tilde{y}=V^{-1}AU\tilde{x}$，$\tilde{y}=\left[ \begin{array}{c:c}\begin{matrix} \sigma_1&&\\&\ddots&\\&&\sigma_r  \end{matrix}&0\\ \hdashline0&0  \end{array}\right]\tilde{x}$。此时$\tilde{x}$和$\tilde{y}$解耦，$n$入$m$出的静态系统解耦成了$r$个单入单出的静态系统。
2. 最大奇异值的含义：$\overline{A}^TA$是非负定的，由非负定最大特征值的极值刻画可得：$\sigma_{\max}=\sqrt{\max \frac{\overline{x}^T\overline{A}^TAx}{\overline{x}^Tx}}$，其中$\norm{x}\ne0$，进一步化简为$\sigma_{\max}=\sqrt{\max \frac{\norm{Ax}^2}{\norm{x}^2}}=\max\sqrt{\frac{\norm{Ax}^2}{\norm{x}^2}}=\max\frac{\norm{Ax}}{\norm{x}}$。也就是说最大奇异值为线性映射$A$将源映射为像的过程中，对长度的最大放大作用。这也是由向量的二范数导出的矩阵二范数。
3. 矩阵$A$是$m\times n$的，$n$阶矩阵$\overline{A}^TA$和$m$阶矩阵$A\overline{A}^T$的秩都是$\rank(A)=r$。都有$r$个非零特征值，且这$r$个特征值是相同的，重根情况也是一样的。这两个矩阵除了这$r$个相同的非零特征值以外，其余的特征值都是0。
7. 

# 向量与矩阵的范数

1. $V$是$C$上的线性空间。映射$\norm{\cdot}:V\to R$。如果满足以下三条性质，则称之为范数：
   1. 正性，$\norm{x}>0$，当$x\ne0$时。
   2. 正齐性，$\norm{\alpha k}=|k|\norm{\alpha}$，$k$是任意复数。
   3. 三角不等式，$\norm{x+y}\le\norm{x}+\norm{y}$。
2. $C^n$中的经典的范数例子：
   1. 1-范数：$\norm{x}_1=\Sigma_{i=1}^n|x_i|$。
   2. 2-范数：$\norm{x}_2=\sqrt{\Sigma _{i=1}^n|x_i|^2}$。也就是由标准内积定义的长度。
   3. p-范数：$\norm{x}_p=(\Sigma _{i=1}^n|x_i|^p)^{1/p}$，其中$p\ge1$。能够兼容前面的1-和2-范数。
   4. 无穷范数：$\norm{x}_{\infty}=\max\{ |x_i|,i=1,\cdots,n \}$。
3. 引入范数的目的：可以在抽象空间中研究距离（产生了距离空间，也称为度量空间），进而研究序列的收敛（距离越来越近）。从而将数学分析中的方法引入到抽象的集合上去。
4. $\lim_{n\to\infty}S_n=S_0$可以转换为$\lim_{n\to\infty}d(S_n,S_0)=0$。前者是线性空间$S$中的，后者是实数域上的。
5. 由标准内积定义的长度是2-范数，如果某个范数不满足平行四边形公式，那么它就不能是由某个内积导出的。
6. 用内积定义的长度比用范数定义的长度具有更丰富的几何结构，除了长度之外，还可以讨论夹角，垂直等问题。
7. 赋范线性空间：定义了范数的线性空间。比内积空间更加抽象。
8. 矩阵范数：$\norm{\cdot}:\{ 全体矩阵\}\mapsto R_+$。要求满足以下4点：
   1. 正性：$\norm{A}>0$，当$A\ne0$时。
   2. 正齐性：$\norm{kA}=|k|\norm{A}$。
   3. 三角不等式：$\norm{A+B}\le\norm{A}+\norm{B}$。也成为加法相容性
   4. 乘法相容性：$\norm{AB}\le\norm{A}\norm{B}$。

9. 矩阵范数并不是针对某一种$m\times n $的矩阵，而是全体矩阵。
10. 将由向量的$p-$范数导出的矩阵范数，称为矩阵的$p-$范数。$\norm{A}_p=\max \frac{\norm{Ax}_p}{\norm{x}_p}$，其中$x\ne0$。也称为诱导范数。
    1. 矩阵的1-范数：$\norm{A}_1=\max_j\sum_{i=1}^m|a_{ij}|$，计算每一列所有元素的绝对值的和，然后找出最大的。也称为列和范数。
    2. 矩阵的2-范数：$\sqrt{\lambda_{\max}(\overline{A}^TA)}$，也就是$A$的最大奇异值，也成为谱范数。
    3. 矩阵的$\infty$-范数：$\norm{A}_\infty=\max_i\sum_{j=1}^n|a_{ij}|$，计算每一行所有元素的绝对值的和，然后找出最大的。也称为行和范数。

11. 还有一个矩阵的$F-$范数：$\norm{A}_F=(\sum_{i=1}^m\sum_{j=1}^na_{ij}^2)^{1/2}$。

# 向量与矩阵序列的极限

1. $A,A_k\in C^{m\times n}$，其中$k=1,2,\cdots$。当数列极限$\lim_{k\to\infty}d(A_k,A)=0$时，称矩阵序列$A_k$的极限为$A$，即$\lim_{k\to\infty}A_k=A$。其中$d(A_k,A)=\norm{A_k-A}$。
2. 矩阵序列的极限为$A$等价于每个元素$a_{ij}$都有极限，且为$A_{ij}$。矩阵序列的极限等价于$m\times n$个数列的极限。实际上不用范数的概念，也可以定义矩阵的极限，就是每个元素的极限，但是利用范数，可以将$m\times n$个元素的极限转化为1个极限。
3. $m\times n$的矩阵$A$和它的第$i$行第$j$列的元素$a_{ij}$可以相互表示：
   1. $a_{ij}=\alpha_iA\beta_j$。其中$[\alpha_1,\cdots,\alpha_m]=I_m$，$[\beta_1,\cdots,\beta_n]=I_n$。例如$[0,1]\begin{bmatrix}a&b\\c&d  \end{bmatrix}\begin{bmatrix} 1\\0 \end{bmatrix}=c$。得到的结果时第2行，第1列的元素。
   2. $A=\sum_{i,j}a_{ij}E_{ij}$，其中$E_{ij}$是第$i$行第$j$列为1，其余全为0的矩阵。例如$\begin{bmatrix}a&b\\c&d  \end{bmatrix}=a\begin{bmatrix}1&0\\0&0  \end{bmatrix}+b\begin{bmatrix}0&1\\0&0  \end{bmatrix}+\cdots$。
4. 数列级数$\sum_{k=0}^\infty a_k$收敛等价于原数列的部分和序列$\{ s_0,s_1,\cdots, \}$收敛。其中$s_n=a_1+\cdots+a_n$。
5. 数列的收敛就是数列的极限存在。
6. 柯西收敛准则（充要条件）：对于一个数列$\{ x_n\}$，对于任意正数$\varepsilon$，总存在一个正整数$N$，使得当$n>N,m>N$时，$|x_n-x_m|<\varepsilon$。几何意义：该序列中的元素随着序数的增加愈来愈靠近。这个对于无法事先获知极限值的情况特别有用。
7. 级数$\sum_{k=1}^\infty\frac{A^k}{k!}$是收敛的，定义为$e^A$。$A$是一个方阵。同理也可以定义$e^{At}=\sum_{k=1}^\infty\frac{(At)^k}{k!}$。$e^{At}$的计算方法：
   1. 先求$At$的Jordan标准型$P^{-1}(At)P=\begin{bmatrix} J_1t&&\\&\ddots&\\&&J_qt \end{bmatrix}=Jt$。
   2. 将$At=P(Jt)P^{-1}$带入级数定义中，可得$e^{At}=Pe^{Jt}P^{-1}$。
   3. 可以证明当$J$是对角块时，$e^{Jt}$也是对角块，$e^{Jt}=\begin{bmatrix} e^{J_1t}&&\\&\ddots&\\&&e^{J_qt} \end{bmatrix}$。
   4. 针对特定的Jordan块，例如$J_1=\begin{bmatrix} c_1 & 1 & & & \\ & c_1 & 1 & & \\ & & c_1 & 1 & \\ & & & c_1 & 1 \\ & & & & c_1 \end{bmatrix}=c_1I+N$，是$r_1$阶Jordan块，其中$N=\begin{bmatrix} 0 & 1 & & & \\ & 0 & 1 & & \\ & & 0 & 1 & \\ & & & 0 & 1 \\ & & & & 0 \end{bmatrix}$，经计算，可得$N^k$相当于将次对角线（全是1的那个）向右上平移一格。例如$N^2=\begin{bmatrix} 0 & 0 &1 & & \\ & 0 & 0 &1 & \\ & & 0 & 0 &1 \\ & & & 0 & 0 \\ & & & & 0 \end{bmatrix}$。因此$N^k=0$，当$k>r_1-1$时。这样的矩阵称为幂零矩阵。
   5. 将$J_it$带入，$e^{J_it}=e^{c_1It+Nt}=e^{c_1It}e^{Nt}=e^{c_1t}\sum_{k=0}^{r_1-1}\frac{(Nt)^k}{k!}=e^{c_1t}\begin{bmatrix}1&t&\cdots&\frac{t^{r_1-1}}{(r_1-1)!}\\&\ddots&\ddots&\vdots\\&&\ddots&t\\&&&1    \end{bmatrix}$。
   6. 最后拼成整个分块对角矩阵即可得到$e^{At}$。

8. 如果$AB=BA$，那么$e^{A+B}=e^Ae^B$。

# 向量与矩阵值函数

1. $A(\cdot):[a,b]\to C^{m\times n}$。函数值是向量或矩阵，也就是系统的出口是$m\times n$的。入口不一定是1个。
2. 定义向量和矩阵值函数的目的主要是用来研究微积分。
   1. 当$\lim_{t\to t_0}\norm{A(t)-A}=0$，$\lim_{t\to t_0}A(t)=A$。
   2. $A'(t_0)=\frac{\text{d}}{\text{d}t}|_{t=t_0}A(t)=\lim_{\Delta t\to 0}\frac{A(t_0+\Delta t)-A(t_0)}{\Delta t}$。
   3. $\int_a^bA(t)\text{d}t=C$，即。将$[a,b]$分割为$n$个区间，得到$a\le t_0\lt t_1 \lt\cdots\lt t_n=b$。记$\Delta t_i=t_{i+1}-t_i$。$t_i<\xi_i<t_{i+1}$。若$\lim_{\max |\Delta t_i|\to0}\sum_{i=1}^nA(\xi_i)\Delta t_i=C$，则称定积分$\int_a^bA(t)\text{d}t=C$。
3. 导数和积分都是定义在极限之上的。对矩阵值函数进行求极限，求导，积分，都可以转化为对矩阵中的每个元素进行相应的运算。
3. $(e^{At})'=Ae^{At}=e^{At}A$。
3. 系统的稳定：有界初值导致有界输出。渐进稳定：在稳定的基础上，当$t\to\infty$时，输出趋于0。
3. 
3. 
3. 
3. 
4. 
5. 
6. 
7. 
8. 
9. 
10. 
11. 
12. 
13. 
14. 
15. 
16. 
17. 

# 二次型与正定矩阵

1. 二次型就是含有$n$个变量的二次齐次多项式，即$f(x_1,x_2,\cdots,x_n)=a_{11}x_1^2+a_{22}x_2^2+\cdots+a_{nn}x_n^2+2a_{12}x_1x_2+\cdots+2a_{n-1,n}x_{n-1}x_n$。
2. $X^TQX$等价于$X^T\frac{(Q^T+Q)}{2}X$，因为$X^TQX$是一个数，因此$X^TQX=(X^TQX)^T=X^TQ^TX$。所以研究非对称矩阵的二次型没有意义，非对称矩阵可以分解为一个对称矩阵$\frac{Q+Q^T}{2}$和一个反对称矩阵$\frac{Q-Q^T}{2}$的和。而这个反对称矩阵的二次型恒为0。因此默认二次型对应的矩阵都是对称的。
3. 根据二次型函数$f(x)=x^TAx$可以判定矩阵的正定性：
   1. 若$f(x)>0,x\ne0$，则$f$为正定二次型，$A$为正定矩阵。
   2. 若$f(x)\ge0,x\ne 0$，则$f$为半正定二次型，$A$为半正定矩阵。
   3. 若$f(x)<0,x\ne0$，则$f$为负定二次型，$A$为负定矩阵，$-A$即为正定矩阵。
   4. 若$f(x)\le0,x\ne0$，则$f$为半负定二次型，$A$为半负定矩阵。
   5. 如果以上都不是为不定矩阵。
4. 对于$n$阶是对称矩阵，如果$A$的所有顺序主子式都>0，则$A$是正定矩阵。$k$阶顺序主子式是包含矩阵前$k$行和前$k$列的子式。
5. 复对称矩阵称为Hermite矩阵。研究对称矩阵的原因是二次型和对称矩阵是等价的。
5. 
5. 
5. 
5. 
