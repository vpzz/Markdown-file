# 绪论

1. 计算机图形学是从模型到图片，计算机视觉是从图片到模型，让计算机来理解图片。现在也有视觉和图形学结合的，先让计算机理解图片，然后继续创作出新的图片，例如AI换脸。

2. ![image-20210521162829103](计算机图形学和OpenGL.assets/image-20210521162829103.png)

3. 特效应该是图形学中比较简单的，应为日常生活中比较少见，不容易看出问题，最难的是渲染常见的物品的逼真感。

4. 图形学中的向量一般都用单位向量$\hat{a}$。$b_{\perp}$是向量$\vec{b}$在向量$\vec{a}$上的投影，$=(b\cdot\hat{a})\hat{a}$。

5. 向量的叉乘：
   $$
   \vec{a}\times\vec{b}=\begin{pmatrix}y_az_b-z_ay_b\\z_ax_b-x_az_b\\x_ay_b-y_ax_b\end{pmatrix}
   $$

6. 也可以写成矩阵表示，$A^*$是$\vec{a}$​的对偶矩阵：
   $$
   \vec{a}\times\vec{b}=A^*b=\begin{pmatrix}0&-z_a&y_a\\z_a&0&-x_a\\-y_a&x_a&0\end{pmatrix}\begin{pmatrix}x_b\\y_b\\z_b\end{pmatrix}
   $$

7. 叉乘可以用来判断平面向量的左右，例如$\vec{a}\times\vec{b}$的方向是$+Z$方向，则说明$\vec{b}$在$\vec{a}$的左侧：

8. <img src="计算机图形学和OpenGL.assets/image-20210521202431410.png" alt="image-20210521202431410" style="zoom:50%;" />

9. 叉积还可以用来判定平面上点P是否在三角形ABC内。分别用$\vec{AB}\times\vec{AP}$，$\vec{BC}\times\vec{BP}$，$\vec{CA}\times\vec{CP}$。三个结果向量如果是同向的，则P点在三角形内部。这里不用要求ABC的顺序必须是逆时针或者顺时针。

10. <img src="计算机图形学和OpenGL.assets/image-20210521202620105.png" alt="image-20210521202620105" style="zoom:50%;" />

# 变换

1. 在引入齐次做标签，所有的变换矩阵应用的目标都是点的坐标，而非向量坐标。引入了齐次变换后，可以将矩阵作用于向量，可以发现平移变换对于向量没有效果。
2. 旋转默认是以原点为中心，逆时针转动。二维旋转矩阵$R_\theta$为$\begin{pmatrix}\cos\theta&-\sin\theta\\\sin\theta&\cos\theta\end{pmatrix}$。
3. 平移变换是非齐次的，不属于线性变换，因为不能表示为一个矩阵左乘原来的位置坐标。常见的线性变换有：缩放，旋转（2维绕点，3维绕轴）。
4. 错切变换：$y'=y;x'=x+ay$。写成矩阵形式为变换为$\begin{pmatrix}x'\\y'\end{pmatrix}=\begin{pmatrix}1&a\\0&1\end{pmatrix}\begin{pmatrix}x\\y\end{pmatrix}$。
5. <img src="计算机图形学和OpenGL.assets/image-20240902232414977.png" alt="image-20240902232414977" style="zoom: 80%;" />

## 齐次坐标

1. 引入齐次坐标的目的是为了将平移变换和其他的线性变换以统一的形式表示。

2. 在平面2维点和向量的坐标最后再加上一维。向量具有平移不变性，而点不具有。这样的规定也是符合向量和点之间的关系的，即向量=点-点。

   ```c++
   2D point  = (x,y,1)^T  //这样两个点坐标的差就是向量了，例如任意点(x,y,1)和原点坐标(0,0,1)的差就是该点的位置向量(x,y,0)。
   2D vector = (x,y,0)^T
   ```

3. 向量+向量结果是向量（平行四边形法则），向量+点结果是点（将该点沿着向量移动），点-点结果是向量。点+点本来是无意义的，而在此被赋予新的含义：(x,y,w)，其中w≠0，所表示的点和(x/w,y/w,1)是相同的。此时点和点相加的几何意义就是两个点的中点，例如$(0,1,1)+(1,0,1)=(1,1,2)=(0.5,0.5,1)$。

4. 点的权重坐标可以不同，但都必须是非零的，该点的实际坐标是齐次坐标/权重，例如$(2,4,6,2)$和$(1,2,3,1)$是同一个点。点和点做差获得向量前必须要统一权重，刚才例子的结果就是$(0,0,0,0)$​，也就是零向量。

5. 可以发现，实数乘以向量，等价于向量的伸缩，这作用在齐次坐标上也是一样的，权重始终为0。非零实数乘以点，每个维度和权重都会参与乘法，因此结果还是一个点，和没乘之前是同一个点。

6. 仿射变换=线性变换+平移变换。先应用线性变换，再平移变换。所有的仿射变换都可以写成齐次坐标的形式。
   $$
   \begin{pmatrix}x'\\y'\end{pmatrix}=\begin{pmatrix}a&b\\c&d\end{pmatrix}\cdot\begin{pmatrix}x\\y\end{pmatrix}+\begin{pmatrix}t_x\\t_y\end{pmatrix}
   $$

7. $$
   \begin{pmatrix}x'\\y'\\1\end{pmatrix}=\begin{pmatrix}a&b&t_x\\c&d&t_y\\0&0&1\end{pmatrix}\cdot\begin{pmatrix}x\\y\\1\end{pmatrix}
   $$

   

8. 这样平移变换就可以写成线性变换了。可以发现，下式对于向量，结果仍然是该向量。
   $$
   \begin{pmatrix}x'\\y'\\w'\end{pmatrix}=\begin{pmatrix}1&0&t_x\\0&1&t_y\\0&0&1\end{pmatrix}\cdot\begin{pmatrix}x\\y\\1\end{pmatrix}=\begin{pmatrix}x+t_x\\y+t_y\\1\end{pmatrix}
   $$

9. 变换就是做矩阵乘法，由于矩阵乘法没有交换律，因此变换的顺序不能随意交换。

10. 如果要绕任意一个点旋转，可以先将图形平移，使得该点位于原点，然后旋转，最后再反向平移，使得该点回到原来的位置。

11. ![image-20210521221837640](计算机图形学和OpenGL.assets/image-20210521221837640.png)

12. 三维空间中点和向量的齐次坐标：

    ```c++
    3D point  = (x,y,z,1)^T  //注意，这不是四元数。
    3D vector = (x,y,z,0)^T
    ```


## 视图变换

1. 视图（相机）变换：把三维场景变换到二维上。
2. 拍照的类比，MVP变换：
   1. 人员就位，模型model变换，例如调整物体之间的相对位置。
   2. 相机就位，视图view变换，例如调整相机的位置和方向。
   3. 拍照，投影projection变换，正交或透视。
3. 相机的摆放需要以下几个变量：
   1. 相机的位置，position  $\vec{e}$。
   2. 看的方向，look-at  $\vec{g}$，也就是镜头的轴线。
   3. 上方向，up direction  $\vec{t}$。
4. 如果相机和模型一起移动，那么view视图是不变的，因此二者只要一个移动就可以了。一般约定固定相机不动，让模型绕着相机运动。相机的位置在原点，看着-Z，上方向是Y。正好类似于人眼观察屏幕，此时屏幕的原点在左下角，向右为x正向，向上为y正向。
5. 模型和相机的位置都可以用全局坐标系来描述，运用完模型视图变换后，相机会移动到全局坐标系的原点。
6. 依次进行如下操作，将任意位置的相机摆放到标准位置（这样在后续的计算中有好处）：
   1. 将$\vec{e}$移动到原点
   2. 将$\vec{g}$旋转到-Z方向
   3. 将$\vec{t}$旋转到Y方向
   4. 将$\vec{g}\times\vec{t}$旋转到X方向 ，做完2,3步，这一步自然完成，不用额外操作。
7. 将模型和相机应用相同的方法，得到的view视图就是不变的。模型变换和视图变换都会应用在模型上，通常被称为模型视图变换。
8. 整体变换就是$M_{view}=R_{view}T_{view}$，先应用平移，再应用旋转。
9. 平移变换如下，其中相机的位置坐标为$(x_e,y_e,z_e,1)$。
10. <img src="计算机图形学和OpenGL.assets/image-20240903141633072.png" alt="image-20240903141633072" style="zoom:67%;" />
11. 求将任意轴旋转到标准轴的矩阵比较麻烦，可以先求标准轴到任意轴的旋转，然后求逆（转置）矩阵（正交矩阵）即可。
12. 下面的左侧矩阵会将标准正交基向量旋转到对应的$\vec{g}$和$\vec{t}$还有$\vec{g}\times\vec{t}$。可以将$R_{view}^{-1}$应用到x轴正向单位向量$(1,0,0,0)$，结果就是$\hat{g}\times\hat{t}$。
13. ![image-20210521230620683](计算机图形学和OpenGL.assets/image-20210521230620683.png)

## 投影变换

1. 常见的两种投影变换：正交（Orthographic）和透视（Perspective）。人眼的成像是透视投影，应用最广泛，正交投影多用于工程制图。

2. 立方体的正交投影和透视投影，可以发现对于正交投影，三维的平行线，投影之后仍然是平行的。而透视投影不是。

3. ![image-20210521231649913](计算机图形学和OpenGL.assets/image-20210521231649913.png)

4. 一个平面内的平行线是不会相交的，而将其投影到另一个平面后，就不一定平行了。

5. 二者的区别是，透视投影会表现出近大远小的效果，道理我都懂，但是鸽子为什么这么大。

6. 透视投影：相机看做一个点，相机和投影面构成一个四棱锥，将在一定距离范围内，从near clip plane到far clip plane之间模型投影到near clip plane。投影四棱锥前后两个面的中心点法线是通过原点的。

7. <img src="计算机图形学和OpenGL.assets/image-20240903193845555.png" alt="image-20240903193845555" style="zoom:67%;" />

8. 透视投影的相机如果在无限远处，就变成了正交投影。

9. 对于正交投影，需要指定投影长方体，只有在这个范围内的模型才会被投影到Near平面上。

10. 获取标准视图下的正交投影的方法：

    1. 先进行模型视图变换，调整好相机的位置。
    2. 扔掉Z坐标，相当于投影到xy平面上。
    3. 将投影内容平移缩放到$[-1,1]^2$范围内。

11. 实际工程中是使用如下方法：获取模型的三个方向的边界（也是人为指定投影立方体的范围），从左到右，从下到上，从远到近。，将该立方体的重心平移缩放到$[-1,1]^3$。此时不会丢弃Z坐标，因为它保存了前后的信息，决定了谁会覆盖谁。

12. 平移缩放到最终的正方体$[-1,1]^3$，称为正则立方体，这一步会改变模型的长宽比，失真。在模型，视图，投影变换都完成后，还会进行视口变换，这时会进行修正，还原失真前的情况。

13. 需要注意的是，由于相机的观察是沿着-Z方向的，因此远处的坐标值<近处的坐标值。这是由于使用了右手坐标系的原因（注意，即使使用左手系，相机还是会朝着屏幕内观察，不过此时就是+Z方向了）。f表示far，n表示near。一些API会使用左手系，这样近处物体的z坐标就比较小。

14. ![image-20240903195205189](计算机图形学和OpenGL.assets/image-20240903195205189.png)

15. 正交投影的公式：先平移，然后缩放。

16. <img src="计算机图形学和OpenGL.assets/image-20240903161250553.png" alt="image-20240903161250553" style="zoom:67%;" />

17. 获取标准视图下的透视投影：

    1. 先将棱台（frustum）的远处平面缩放成和近处平面同样大小，此时变成下图右侧。近平面上的所有点不动，远处平面点的Z值不变，远平面的中心不动。容易错误地认为中间的任意一点的z值不变，毕竟远近两个面的z都不变，实际不是的。
    2. 再做正交投影即可。

18. ![image-20210522002800072](计算机图形学和OpenGL.assets/image-20210522002800072.png)

19. 透视投影变换矩阵：$M_{persp}=M_{ortho}M_{persp\to ortho}$。

20. 上边左图中的棱台的四条侧棱相交于一点，就是相机的位置。远处平面上的每个点都在近处平面上有一个对应的点，二者的连线通过相机位置。

21. 用Y-Z平面切割棱台，得到如下视图，其中有2个相似三角形，（x，y，z）是棱台内的任意一点，（x'，y'，z'）为任意点和相机的连线与近处平面的交点。因此可以得出远处平面上的点的y坐标要变成和近处相对应的点的坐标，需要乘以$n/z$。用X-Z平面切割也可以得到类似的结果。因此$y'=\frac{n}{z}y$，$x'=\frac{n}{z}x$。

22. ![image-20240903201312688](计算机图形学和OpenGL.assets/image-20240903201312688.png)

23. 此时可以确定，任一点(x，y，z，1)都会被映射到(nx/z，ny/z，unknown，1)。对结果的点的4个坐标同时乘以z（显然z≠0，还是同一个点），变为（nx，ny，unknown，z）。通过这个来推断矩阵的一些元素的值。

24. ![image-20240903203129871](计算机图形学和OpenGL.assets/image-20240903203129871.png)

25. 推断出的结果为：

26. ![image-20240903203202747](计算机图形学和OpenGL.assets/image-20240903203202747.png)

27. 此时还有4个未知数，可以将近处（x，y，n，1）和远处（x，y，f，1）平面上的点映射前后不变的性质应用即可得到这4个未知数。

28. $M_{persp\to ortho}=\begin{pmatrix}n&0&0&0\\0&n&0&0\\0&0&n+f&-nf\\0&0&1&0\end{pmatrix}$

29. 该矩阵会将任意点（x，y，z，1）映射到（nx，ny，nz+zf-nf，z）。结果点的z坐标为$(n+f-nf/z)$。将其和z做差，结果为$(f-z)(z-n)/z$，由于z处在$[n,f]$之间，且z恒<0，因此结果为负数，即该点会被推向远方。

30. 近平面上的矩形和相机组成一个视锥，有两个重要参数，宽高比width/height和垂直可视角度 fovY，可得$\tan fovY/2=height/(2n)$。通过这两个参数也可以计算出水平可视角度：

31. $$
    Aspect\quad ratio=\tan(fovX/2)/\tan(fovY/2)
    $$

    

32. ![image-20210522004728129](计算机图形学和OpenGL.assets/image-20210522004728129.png)

33. 相机的广角镜头是指可视角度大。

# 光栅化

1. 光栅 raster就是德语中的屏幕。光栅化就是画在屏幕上。
2. 屏幕空间：原点在左下角，向右为X正向，向上为Y正向。像素是当成有面积的，即需要考虑半个像素。
3. 如下像素组，一共有4*3=12个像素，下标从(0,0)到(3,2)。像素的范围是$[0,0]\times[4,3]$。像素(x,y)的中心是在(x+0.5,y+0.5)的位置。
4. ![image-20210522010223305](计算机图形学和OpenGL.assets/image-20210522010223305.png)
5. 视口viewport变换，z方向没有变化，还是$[-1,1]$：
6. ![image-20210522011558853](计算机图形学和OpenGL.assets/image-20210522011558853.png)
7. 隔行扫描，前一帧使用奇数行，后一帧使用偶数行，交替进行，利用人眼的视觉暂留，减小传输带宽，不过对于高速运动的画面会撕裂。1080p就表示逐行扫描，1080i就表示隔行扫描。
8. 显示器显示的画面就是内存（或显存）中的一块区域，可以绘制多块，交替显示。
9. LCD是液晶显示器，通过液晶对光的偏振效应。LED是发光二极管，可以做成点阵的，例如商业LED屏幕。区别是LCD是需要背光的，LED是自发光的。
10. 三角形是最基础的多边形，始终保持一个平面，内外定义清晰。
11. 经过MVP变换，视口变换，就可以得到每个三角形在屏幕空间中的坐标（实数）。
12. 光栅化就是确定下图中每个像素的的颜色取值。一个简单的方法就是采样（计算一个函数在特定点的值），用像素的中心对三角形面进行采样，即计算像素中心是否在三角形内部。
13. <img src="计算机图形学和OpenGL.assets/image-20210522013232356.png" alt="image-20210522013232356" style="zoom:50%;" />
14. 实际上没有必要对所有像素都计算一遍，只需要计算三角形的包围盒就可以了，下图中最左侧的那一列不用计算都知道不会在三角形内部。
15. <img src="计算机图形学和OpenGL.assets/image-20210522013432900.png" alt="image-20210522013432900" style="zoom:50%;" />
16. 两种屏幕的次像素排列方式，标准的RGB排列和钻石排列。可以看出钻石排列中，绿色的像素更多，因为人眼对绿色更敏感。
17. <img src="计算机图形学和OpenGL.assets/image-20210522014448508.png" alt="image-20210522014448508" style="zoom:50%;" />
18. 如果直接对上述结果进行绘制，就会出现如下锯齿Jaggies：
19. <img src="计算机图形学和OpenGL.assets/image-20210522015426895.png" alt="image-20210522015426895" style="zoom:50%;" />

# 反走样

1. 抗锯齿=反走样=antialiasing。避免出现artifact，也就是失真。
2. 欠采样就是信号的变化太快，采样速率太慢了。
3. 摩尔纹，将左图的奇数行和列都去除掉。属于空间的欠采样。可以发现对于领带和衣服部分，由于像素的变化太剧烈，因此欠采样产生的失真很明显，而对于人脸部分，由于本身像素变化不大，欠采样后也不产生明显的失真。
4. ![image-20240904213249519](计算机图形学和OpenGL.assets/image-20240904213249519.png)
5. 车轮效应（观察到反向转动的车轮）是时间上的欠采样。
6. 可以通过先将边界突兀的三角形模糊化，再进行采样。模糊就相当于低通滤波（突变的边界意味着空间的变化频率太高了，也就是梯度太大了，低通滤波后，就）了。如果先采样，再模糊则达不到反走样的效果。
7. ![image-20210522103429001](计算机图形学和OpenGL.assets/image-20210522103429001.png)
8. 左侧为初始的锯齿，右侧为先模糊再采样的结果，较好地消除了锯齿。
9. ![image-20240904213738314](计算机图形学和OpenGL.assets/image-20240904213738314.png)
10. blurred（模糊） aliasing：先进行采样，再进行模糊，则会得到如下结果，不推荐。
11. ![image-20240904214019378](计算机图形学和OpenGL.assets/image-20240904214019378.png)
12. 使用下图中的采样频率对蓝色和黑色的曲线进行采样，会得到相同的离散点。
13. 走样（混叠 aliasing）：两种不同频率的信号的采样结果相同。
14. ![image-20210522104429281](计算机图形学和OpenGL.assets/image-20210522104429281.png)
15. 图像的频率，像素值在空间的变化快慢。
16. <img src="计算机图形学和OpenGL.assets/image-20210522104857066.png" alt="image-20210522104857066" style="zoom: 80%;" />
17. 高通滤波后的结果，也就是在频域中将中心的低频数据全部清除掉，然后再还原到空间域：
18. <img src="计算机图形学和OpenGL.assets/image-20210522105024618.png" alt="image-20210522105024618" style="zoom: 80%;" />
19. 低通滤波后的结果，会出现类似于水波纹的情况：
20. <img src="计算机图形学和OpenGL.assets/image-20210522105311126.png" alt="image-20210522105311126" style="zoom: 80%;" />
21. 卷积定理：时域（空间域）上的信号卷积等价于频域中的信号傅里叶变换的乘积，反之也成立。由于乘积更方便计算，因此可以将信号变换到频域上进行乘积，然后再逆变换回时域。
22. 信号处理中很多时候（例如移动平均）就是利用卷积定理来简化计算，将时域的卷积变成频域的乘积。而采样则是应用了卷积的逆定理，将时域的乘积变成频域的卷积。
23. 对下面的这幅图进行卷积（就是加权平均）计算，该滤波器主要在低频部分值较大，是低通滤波。如果卷积核扩大，变成9x9的，那么低通滤波器的截止频率会降低。极限的情况，1x1的卷积核，相当于没有滤波，即截止频率无限大。
24. <img src="计算机图形学和OpenGL.assets/image-20210522105700719.png" alt="image-20210522105700719" style="zoom: 80%;" />
25. 所有的移动平均都是低通滤波。
26. 采样就是重复频域上的内容：采样需要时域（空间域）上的离散采样函数和被采样函数乘积，相当于频域上傅里叶变换的卷积。采样函数的傅里叶变换是一个冲激串。一个函数和冲激函数的卷积就是将它平移到冲激函数的中心位置。
27. ![image-20210522110350985](计算机图形学和OpenGL.assets/image-20210522110350985.png)
28. 采样频率决定了卷积核的间隔，如果采样频率越低，卷积核间隔就过小，则会造成频域上的混叠。
29. 奈奎斯特定理：采样频率>=2信号最高频率，才不会引起混叠。
30. ![image-20210522110549666](计算机图形学和OpenGL.assets/image-20210522110549666.png)
31. 增加采样率，也就是使用像素点更密集的屏幕，可以减少走样。但是通常说的反走样是在同样的屏幕上进行的。
32. 模糊操作就是进行低通滤波，这样信号的最高频率变小了，所需的最小采样频率就降低了。
33. ![image-20210522111057921](计算机图形学和OpenGL.assets/image-20210522111057921.png)
34. MSAA 多重采样反走样：考虑每一个像素内部的亚像素，例如将一个像素分为4x4。然后分别计算这16个亚像素的中心是否在三角形内部，从而计算出每个亚像素中心的取值。然后将这16个亚像素进行平均，就得到整个像素的值。
35. 该方法只是进行反走样的第一步，即模糊操作。
36. <img src="计算机图形学和OpenGL.assets/image-20210522112028796.png" alt="image-20210522112028796" style="zoom:50%;" />
37. 正常采样的结果：
38. <img src="计算机图形学和OpenGL.assets/image-20210522112312404.png" alt="image-20210522112312404" style="zoom:50%;" />
39. 进行2x2多重采样：
40. ![image-20210522112509084](计算机图形学和OpenGL.assets/image-20210522112509084.png)
41. 多重采样平均后的结果。
42. ![image-20210522112538899](计算机图形学和OpenGL.assets/image-20210522112538899.png)
43. 每个像素模糊后的结果。在此基础上采样就是它本身。
44. ![image-20210522112732455](计算机图形学和OpenGL.assets/image-20210522112732455.png)
45. 其他常用的抗锯齿方案：FXAA，TAA。
46. 超分辨率：将一张小图变大，但是又尽可能地消除锯齿。

# 深度缓冲

1. 由油画的绘制得到的启发，先画远处的，再画近处的，新画的会覆盖之前的。不过需要事先确定那些面是远的，那些面是近的。但是如下的情况，面的远近顺序是无法定义的。
2. ![image-20210522142323706](计算机图形学和OpenGL.assets/image-20210522142323706.png)
3. 既然面的远近无法定义，那就逐个像素来记录要绘制的颜色。一个像素范围内可能有多个面前后分布。
4. 深度缓冲算法会在生成帧缓冲frame buffer（存储每个像素的颜色值）的同时生成一个深度缓冲depth buffer（存储每个像素距离模型最近的深度信息）。
5. 利用深度缓冲来维护遮挡信息。深度定义为模型上的点到相机的距离。因此Z坐标越小，距离越远，深度越大。
6. 可以看到，红圈标出来的模型部分，距离相机最近，深度最小。因此在深度缓冲中表现较暗。越远的地方，深度越大，颜色越亮。
7. ![image-20210522143112684](计算机图形学和OpenGL.assets/image-20210522143112684.png)
8. 深度缓冲算法，最重要的可视化算法，硬件实现：
   1. 先将帧缓冲初始化为纯黑色，深度缓冲初始化为无穷远$+\infty$。C++中是有无穷大这个定义的。
   2. 从模型的任意部分开始绘制，像素会记录下来当前像素对应的模型的颜色（放到帧缓冲中），还有深度（放到深度缓冲中）。
   3. 接着绘制，如果同一个像素遇到新的要覆盖的内容，会检查新像素对应模型的深度，如果比当前像素对应的模型深度浅，则会覆盖当前像素，即修改帧缓冲中的颜色和深度缓冲中的深度。
9. 
10. ![image-20210522143728353](计算机图形学和OpenGL.assets/image-20210522143728353.png)
11. 在初始屏幕上分别绘制两个三角形。最终的结果是和绘制的顺序无关的。假设不会有模型上投影到同一个像素的两个点具有相同的深度。
12. ![image-20210522144049998](计算机图形学和OpenGL.assets/image-20210522144049998.png)
13. 如果使用了MSAA，那么深度缓冲需要记录每个亚像素的结果。

# 着色

1. 着色shading：明暗和颜色。
2. 同样的几何体，例如一个球，金属球和塑料球还有玻璃球看上去不同是因为材质material不同。和光线的相互作用不同。
3. 冯反射模型是一个较为简单的模型。
4. 模型上任何一个点都会接收到一个环境光，主要是模型之间的漫反射叠加的结果。
5. 下图中的区域可以分为三大部分，高光，漫反射，环境光。
6. ![image-20210522151251604](计算机图形学和OpenGL.assets/image-20210522151251604.png)
7. 计算光线在从光源出发在表面上的一个点反射，被另一个位置的相机观测到：需要考虑的参数有：
   1. 光线的方向$\vec{l}$。
   2. 表面的法向$\vec{n}$。
   3. 观察的方向$\vec{v}$。
   4. 表面的参数，例如颜色，光泽度。
8. ![image-20210522151805397](计算机图形学和OpenGL.assets/image-20210522151805397.png)
9. 着色shading是局部的，不考虑着色点被其他模型遮挡，产生阴影shadow。着色的时候只考虑光源，着色点，观察点。从下面这张图可以看出来，光源在左上角，而红圈部分真实情况下是会在球体的阴影区域。而着色时不考虑阴影，所以仍然是光亮的。
10. ![image-20210522152358335](计算机图形学和OpenGL.assets/image-20210522152358335.png)
11. 漫反射：光线入射到一个平面后，会被均匀地向各个方向反射。
12. ![image-20210522152753993](计算机图形学和OpenGL.assets/image-20210522152753993.png)
13. 入射光线和表面法线的夹角决定漫反射的强度，这个和人眼的观测无关，这个是能量接受多少的问题。例如地球上的四季是因为公转会导致太阳的高度角变换。虽然太阳位于地球轨道的焦点，公转也会影响地日距离。而高度角变化对温度的影响要大于地日距离的影响。
14. Lambert's余弦定律。单位面积接收到的能量和面法线与光线的夹角的余弦成正比。可以用光通量的观点解释。
15. 点光源的光强度，和距离平方成反比。
16. <img src="计算机图形学和OpenGL.assets/image-20210522192700899.png" alt="image-20210522192700899" style="zoom:67%;" />
17. 一个点有颜色的原因是因为他会吸收一些颜色，剩下的颜色就是他显现出来的颜色了，因此一个点的颜色除了和它本身有关，还和光的颜色有关。不同材料，光泽度对于颜色的吸收程度不同，即漫反射系数$k_d$不同。漫反射系数可以是对于不同的颜色不同的。
18. ![image-20210522193311637](计算机图形学和OpenGL.assets/image-20210522193311637.png)
19. 漫反射下，如果光源和观测点的位置不变，观察到该点的光强是不随着视线的角度而变化的。
20. 高光是和视线相关的。当观察方向和镜面反射方向接近时，才会观察到高光项。
21. ![image-20210522194440469](计算机图形学和OpenGL.assets/image-20210522194440469.png)
22. 可以引入半程向量，即视线和光线的角平分线。通常高光都是白色的，因此对于各个颜色的高光系数都是差不多的。为了简化，取消了光线和法线的夹角余弦值。
23. ![image-20210522194525135](计算机图形学和OpenGL.assets/image-20210522194525135.png)
24. 上式引入了夹角余弦的p次方，这是因为余弦函数的变化在角度较大时不够快，如果用p=1来计算，会发现高光的区域比较大。通常p的取值在100-200：
25. ![image-20210522194915562](计算机图形学和OpenGL.assets/image-20210522194915562.png)
26. 随着p的增大，高光的区域越来越集中。
27. ![image-20210522195101408](计算机图形学和OpenGL.assets/image-20210522195101408.png)
28. 环境光照，是光线无限次反射后达到的效果，只能进行估计，认为所有点接收到的环境光都是一样大的。环境光的大小和法线方向还有观测方向没有关系。
29. ![image-20210522195226132](计算机图形学和OpenGL.assets/image-20210522195226132.png)
30. ![image-20210522195359410](计算机图形学和OpenGL.assets/image-20210522195359410.png)
31. 光强的衰减只考虑光源到着色点的衰减，不考虑着色点到观察点之间的衰减。
32. 下面这三张图的几何是完全相同的，不同的是从左到右，一个几何面上的着色频率不同，即着色点的密度不同。
    1. 左侧图是一个平面只有一个着色点，在面中心，称为逐平面着色。
    2. 中间图是每个顶点都计算一个法线，然后进行着色。平面内部使用顶点的差值进行计算着色，称为逐顶点着色，也叫Gouraud着色。
    3. 右侧图是先计算顶点的法线，然后平面内部的点（对应到像素的点）的法线使用顶点的法线方向差值计算，然后对内部的点进行着色，称为逐像素着色，phong着色。
33. ![image-20210522195804822](计算机图形学和OpenGL.assets/image-20210522195804822.png)
34. 当几何划分更细时，简单模型的效果也不错。如果面的出现频率提高时，着色频率也就提高。
35. ![image-20210522201202373](计算机图形学和OpenGL.assets/image-20210522201202373.png)
36. 计算顶点的法向的几种方法：
    1. 如果知道几何面想要表示的真实几何的形状，可以通过真实几何计算出来。例如用三角形离散球面![image-20210522201609789](计算机图形学和OpenGL.assets/image-20210522201609789.png)
    2. 大多数情况下是不知道真实几何的，而且真实几何的法线也不好求，可以把顶点所连接的面的法向进行平均。![image-20210522201750284](计算机图形学和OpenGL.assets/image-20210522201750284.png)
    3. 根据三角形的面积对一个顶点相连的不同面的法向进行加权平均。
37. 计算平面内逐像素的法线的步骤：
    1. 先计算出平面的所有顶点的法向。
    2. 使用Barycentric差值计算平面内部任一点的法向。
38. 使用重心坐标进行差值，可以对纹理坐标，颜色，法向量，深度进行差值：
39. 重心坐标是局部坐标，三个变量，三个方程。满足下面的两个方程的点一定在三角形平面内，但是不一定在三角形内。如果重心坐标>=0，则该点在三角形内。
40. <img src="计算机图形学和OpenGL.assets/image-20210522212825272.png" alt="image-20210522212825272" style="zoom:50%;" />
41. 之所以称之为重心坐标，是因为他可以有面积比来计算出来。
42. <img src="计算机图形学和OpenGL.assets/image-20210522213251650.png" alt="image-20210522213251650" style="zoom:50%;" />
43. 三角形的重心的重心坐标是$1/3,1/3,1/3$。
44. 待插值的属性通过重心坐标加权求和。
45. <img src="计算机图形学和OpenGL.assets/image-20210522213810819.png" alt="image-20210522213810819" style="zoom:50%;" />
46. 重心坐标的缺点是投影前后同一个点在模型三角形和投影三角形中的重心坐标会变化。因此应该用三维空间的坐标来插值，不能使用投影之后的三角形坐标。因此计算像素中心点的属性时，应该先求得像素中心点对应的模型空间的坐标，然后插值。
47. 图形管线也叫实时渲染管线，就是如何从场景到最后屏幕上显示的图片。可以认为一个fragment就是一个像素，如果使用了MSAA，那就是多个fragment会形成一个像素的颜色。
52. 之所以称之为管线，是因为显卡在设计时，就是不同的部件进行不同的工作。
53. 三角形的记录可以通过两部分来完成：顶点坐标的记录，构成一个三角形的顶点编号。投影只改变顶点坐标，不改变构成三角形的顶点编号之间的关系。
54. ![image-20210522202435176](计算机图形学和OpenGL.assets/image-20210522202435176.png)
55. GPU允许编程来决定如果对顶点和像素进行着色。OpenGL规定的GLSL就是用来写shader的。shader是在GPU上运行的程序。在shader中不需要写for循环为每个顶点或像素着色，只需要定义着色方式，GPU会自动遍历 。分为vertex shader和fragment（pixel） shader两种。
56. 管线会自动调用对应的shader。
57. ![image-20210522205047443](计算机图形学和OpenGL.assets/image-20210522205047443.png)

# 纹理映射

1. 纹理是用来定义着色的时候不同点的属性的。
2. 三维物体的表面是二维的，就像地球仪的表面和地图的关系一样。
3. 纹理就是一张图，它和三维物体的表面是一一对应的，映射关系。主要就是获得模型上的点对应到纹理中的点，三角形的对应关系。希望映射的两个三角形尽可能地少扭曲，大小和连接关系也能对应上。
4. 模型三角形中的每个顶点都被映射到一个纹理坐标(u,v)上。一般认为都在[0,1]之间。
5. <img src="计算机图形学和OpenGL.assets/image-20210522210853522.png" alt="image-20210522210853522" style="zoom:50%;" />
6. 一块纹理是可以重复利用的，就像布料中重复的图案一样。好的纹理设计，应该是在重复的时候看不出来纹理边界。
7. 纹理的使用：
   1. 对于像素的中心，先求得对应的模型坐标和重心坐标。
   2. 根据重心坐标对顶点的纹理坐标插值，计算处该点对应的纹理坐标 uv
   3. 在纹理中根据uv查找
   4. 将纹理颜色当做漫反射系数$K_d$。
8. 纹理也是一张图片，也是由一个个像素构成的，称之为texel，纹素。当空间位置映射到纹理上，坐标不是整数时，像素值的取值有多种方法。
9. 当纹理较小，需要贴的图形较大时，就会出现纹理放大的问题。此时需要考虑纹理坐标在非整数点上取值。下图分别为选取最近的纹理坐标点的插值，
10. ![image-20210522215537776](计算机图形学和OpenGL.assets/image-20210522215537776.png)
11. 双线性插值，水平插值+竖直插值（顺序无所谓）：
12. ![image-20210522215328098](计算机图形学和OpenGL.assets/image-20210522215328098.png)
13. 双三次插值是用邻近的16个纹理像素。每个方向4个，进行三次插值。
14. 对于采用透视投影的图片，同一个像素代表的模型区域的面积是不同的，近处的小，远处的大。如果在远处，还是用像素中心来计算纹理坐标，直接填入，就会出现摩尔纹。
15. 下图中可以看出近处像素和远处像素对应到纹理坐标上的区域大小不同。
16. <img src="计算机图形学和OpenGL.assets/image-20210522220341484.png" alt="image-20210522220341484" style="zoom:50%;" />
17. 解决方法有两种：
    1. 对像素进行超采样，然后平均。不过性能开销太大。
    2. 使用范围查询Mipmap方法。
18. 点查询和范围查询：
    1. 当像素对应的面比较小的时候，需要确定纹理坐标中的值，可以用多个邻近坐标的值进行差值。这就是点查询。
    2. 当像素对应的面比较大的时候，覆盖多个纹理坐标，需要将这个范围内的纹理进行平均作为该像素的纹理。这就是范围查询。
19. <img src="计算机图形学和OpenGL.assets/image-20210522220205257.png" alt="image-20210522220205257" style="zoom:50%;" />
20. mipmap方法，硬件支持，只有在纹理需要被缩小时才有用：
21. 对一张纹理生成一个图像金字塔，增加的文件大小为原始纹理的1/3。
22. <img src="计算机图形学和OpenGL.assets/image-20210522223449283.png" alt="image-20210522223449283" style="zoom:50%;" />
23. <img src="计算机图形学和OpenGL.assets/image-20210522223410021.png" alt="image-20210522223410021" style="zoom:50%;" />
24. 一个像素映射到纹理上大约为右侧的这样一个四边形，也叫泰森多边形，或Voronoi多边形。计算出像素中心映射后的间距的最大值L。将该多边形简化为一个边长为L的正方形。
25. ![image-20210522224018865](计算机图形学和OpenGL.assets/image-20210522224018865.png)
26. ![image-20210522225229725](计算机图形学和OpenGL.assets/image-20210522225229725.png)
27. 如果一个像素在纹理上覆盖了4x4个纹素，那么这16个纹素的平均值，可以通过查询对应纹理金字塔中第2层中的值即可。纹理金字塔的层数$D=round(\log_2L)$。round表示就近取整。也可以不进行取整，在上下两层分别做双线性插值，然后在层间做线性插值，这个称为三线性插值，开销不大。
28. ![image-20210522230412655](计算机图形学和OpenGL.assets/image-20210522230412655.png)
29. 由于mipmap只能查询正方形区域，因此如果纹理映射的畸变比较严重。从下图可以看出，如果对于长方形，也是用正方形mipmap就会多圈到很多纹素，过度平均。
30. ![image-20210522231112114](计算机图形学和OpenGL.assets/image-20210522231112114.png)
31. 各向异性过滤可以对长方形来查询。但是对于斜的长方形仍然无法处理。
32. 各向异性过滤会生成两个方向压扁的纹理，总共的开销为原来的3倍。各向异性2x表示方向上压缩一半，会生成3张额外的图。各向异性4x会生成8张额外的图。只要显存足够大，各向异性不会增加计算力的。
33. ![image-20210522231625268](计算机图形学和OpenGL.assets/image-20210522231625268.png)
34. 在现代GPU中，可以将纹理理解为一块显存区域，可以对这块区域进行点查询和范围查询。纹理不仅仅能替换漫反射系数，可以用来描述任何位置的任意属性。
35. 可以用纹理来描述环境光，这个比点光源好。将任何一个方向来的光都记录下来，然后贴到物体表面，就可以发现反射的。
36. ![image-20210523002555581](计算机图形学和OpenGL.assets/image-20210523002555581.png)
37. 可以将环境光存储到球面上，再拉伸出来，类似于一个360°的图片。不过极点附近会扭曲。
38. <img src="计算机图形学和OpenGL.assets/image-20210523002933991.png" alt="image-20210523002933991" style="zoom: 50%;" />
39. 因此出现了天空盒纹理，将球面上的点映射到立方体的表面上。因此会得到6张图。
40. <img src="计算机图形学和OpenGL.assets/image-20210523003047163.png" alt="image-20210523003047163" style="zoom:50%;" />
41. <img src="计算机图形学和OpenGL.assets/image-20210523003213359.png" alt="image-20210523003213359" style="zoom:50%;" />
42. 例如凹凸感，真正体现出材质感。即不把几何形体变复杂的情况下，使用复杂的纹理来获得复杂的质感。相对高度的变化， 可以体现为法线的变化（法线贴图），从而产生着色上的明暗对比，认为这是有凹凸产生的。
43. <img src="计算机图形学和OpenGL.assets/image-20210523000623212.png" alt="image-20210523000623212" style="zoom: 80%;" />
44. 位移贴图：真的将位移叠加到原始的几何形状上。法线贴图会在几何边缘和阴影露馅。
45. ![image-20210523001740557](计算机图形学和OpenGL.assets/image-20210523001740557.png)

# 几何

1. 几何表示可以有隐式和显式表示。多边形可以用显式方便地表示，曲面用隐式表示有时更方便。
   1. 显式更容易确定哪些点在面上，即曲面的形状。例如直接给出图形上所有的点的坐标。
   2. 隐式更容易确定给定的点是否在面上，将坐标带入方程即可，例如以方程$x^2+y^2+z^2=1$的形式给出球面，就是隐式表示。更一般的为$f(x,y,z)=0$。
   
2. <img src="计算机图形学和OpenGL.assets/image-20210919175601832.png" alt="image-20210919175601832" style="zoom:50%;" />

3. 曲面也可以用参数化进行显式表示，通过变换u,v就可以直接求得三维空间的坐标。不用像隐式那样去解方程。球面的经纬度表示就是这个原理。

4. <img src="计算机图形学和OpenGL.assets/image-20210523004648661.png" alt="image-20210523004648661" style="zoom:50%;" />

5. 可以对简单几何运用布尔运算来生成复杂几何。这个方法称为Constructive Solid Geometry。

6. ![image-20210919180358745](计算机图形学和OpenGL.assets/image-20210919180358745.png)

7. 距离函数方法来定义几何体。给定一个几何，空间的的任一点都可以求得该点到几何表面的最近距离。因此存在一个距离函数。这个距离函数和几何形状一一对应。在几何的表面上，距离函数的取值都为0。距离函数可以构成一个三维的场。

8. 一个物体遮挡住了视口的1/3，然后经过移动，又遮挡了2/3，想要求得中间的状态(即挡住1/2的情况)。如果直接对图像进行blend平均，则会得到3部分中间区域是半透明的，而不是视口被遮挡1/2。可以对每张图计算一个边界的有向距离函数场SDF。然后对AB两个场进行blend平均。然后对sdf进行还原（sdf=0的地方就是边界），就可以得到中间状态了。

9. ![image-20210523013231734](计算机图形学和OpenGL.assets/image-20210523013231734.png)

10. 下面的图是圆形在逐渐靠近正方形，使用SDF进行blend后得出的效果。

11. ![image-20210921143634892](计算机图形学和OpenGL.assets/image-20210921143634892.png)

12. 水平集level-set方法：由于复杂的表面很难求出距离函数的解析式来，因此可以在空间采样，得到离散的距离函数，仅在部分点上有值。这样也可以获得等高面。

13. ![image-20210523014217988](计算机图形学和OpenGL.assets/image-20210523014217988.png)

14. 表示物体的显式方法：
    1. 点云，只用点，需要特别密集，才不会看出来问题。扫描得到输出一般都是点云。一般都会将点云转化为多边形面用于渲染。
    2. 多边形表面，三角形或四边形，最常用的方式。

15. wavefront object file (.obj)文件，通常用来储存点坐标，法线向量，纹理坐标，还有他们的连接方式，多用于研究。v表示顶点坐标，vn表示法线向量。vt表示纹理坐标。f用来定义一个面，第一行表示使用5,1,4三个顶点构成一个三角形。并且三个顶点的纹理坐标分别为1,2,3。三个顶点的法线为1,1,1。

16. <img src="计算机图形学和OpenGL.assets/image-20210921144945380.png" alt="image-20210921144945380" style="zoom:80%;" />

17. 贝赛尔曲线，一种显式的几何表示方法。通过一系列的控制点来定义曲线。曲线要经过起止点P0和P3，且与P0P1，P2P3相切。

18. <img src="计算机图形学和OpenGL.assets/image-20210921145808182.png" alt="image-20210921145808182" style="zoom:50%;" />

19. 三个控制点可以构成二次贝赛尔曲线，使用三个控制点。参数曲线，起点t=0，终点t=1。一共进行三次等比例取点。下面的参数项相当于(1-t+t)^2的展开式。

20. <img src="计算机图形学和OpenGL.assets/image-20210921150707083.png" alt="image-20210921150707083" style="zoom:67%;" />

21. n+1个控制点构成n阶贝塞尔曲线，参数方程为：
    $$
    b^n(t) = b_0^n(t) = \sum_{j=0}^{n}b_jB_j^n(t)
    $$

22. 贝赛尔曲线可以看做是控制点的线性组合。线性组合的系数为伯恩斯坦多项式：
    $$
    B_i^n(t) = C_n^it^i(1-t)^{n-i}
    $$

23. 四个点可以构成三次贝塞尔曲线。

24. <img src="计算机图形学和OpenGL.assets/image-20210921150340587.png" alt="image-20210921150340587" style="zoom:50%;" />

25. 对贝塞尔曲线做仿射变换，等价于对控制点做仿射变换。

26. 对于三次贝赛尔曲线，起始和终止点的切线向量等于3倍的首尾控制点向量。

27. 贝塞尔曲线上任意一点都在控制点形成的凸包内。

28. 高阶贝赛尔曲线不如分段低阶的性质好。例如下面的这个10阶的，难以控制，跟随性差。

29. <img src="计算机图形学和OpenGL.assets/image-20210921195734233.png" alt="image-20210921195734233" style="zoom:50%;" />

30. 最常用的是四个点定义的三阶贝塞尔曲线。ps中的钢笔工具，字体设计中都是用到了这种方法。在软件中，两端贝塞尔曲线交接的地方，控制杆向量都是等大反向，这样可以保证曲线的相切，光滑连接。

31. <img src="计算机图形学和OpenGL.assets/image-20210921200359698.png" alt="image-20210921200359698" style="zoom:50%;" />

32. 贝塞尔曲面可以看做是贝赛尔曲线做双线性插值得到的结果。双三次贝塞尔曲面需要4x4个控制点。首先是一个方向上构造4条空间中的贝塞尔曲线。同时在另一个方向上，对于同一个t的取值，4条贝赛尔曲线上的4个点构成一个新的贝赛尔曲线，这条曲线上的参数值和之前的那个t是相互独立的。这样随着t的变化，新的贝塞尔曲线扫过的曲面就是贝塞尔曲面。因此贝塞尔曲面上任意一个点都有两个参数控制，称为u，v。因此可以将[0,1]x[0,1]映射到任意的双三次贝塞尔曲面上。

33. <img src="计算机图形学和OpenGL.assets/image-20210921203717324.png" alt="image-20210921203717324" style="zoom:50%;" />

34. 两种曲面细分subdivision的方式：

    1. loop细分，只能针对三角形面。将一个三角形变为4个三角形。然后对于新旧顶点分别进行位置调整。
    2. <img src="计算机图形学和OpenGL.assets/image-20210921212056304.png" alt="image-20210921212056304" style="zoom:50%;" />
    3. catmull-clark细分，可以对一般网格面进行。下图左边是细分前的网格，有四边形也有三角形。其中将度≠4的点称为奇异点。经过一次细分后，所有的三角形面都变成了四边形。每个三角形的中心都会增加一个奇异点。之后在进行细分则不会增加奇异点。
    4. 

# OpenGL

1. OpenGL是创建进行实时3D图像的标准。最早是SGI公司开发的。OpenGL以两种形式存在，一个是标注，一个是实现，驱动程序+硬件共同构成他的实现。

2. 2D+透视=3D。如果要看到真正的3D，实际是需要两个眼睛来观察。每只眼睛看到的都是2D的图片，然后由人脑进行拼接，变成3D的。如果只有一个眼睛观察，对距离的感知会下降。

3. GPU是高度并行的。mesa就是OpenGL的纯软件实现，可以运行在CPU上。

4. Windows窗口的默认映射是，原点在屏幕的左上角，向右向下为x,y轴的正向。这种模式对于自上而下绘制文字方便，但是对于绘制图形不方便。视口就是窗口内部用来绘制裁剪区域的客户区域。

5. 大多数使用OpenGL的Windows游戏，还是用了directX的非渲染组件来控制音效，控制功能。

6. OpenGL是一个标准（说明了每个函数的输入，输出，和功能，但是不提供实现细节），由KHrono Group维护。软件使用OpenGL时，可以用各种语言调用。

8. 通常是显卡制造商开发具体的OpenGL库（通常的实现使用C++），一般随显卡驱动附带。所以一般如果OpenGL出问题，就是显卡制造商的锅。厂商的OpenGL实现必须通过OpenGL一致性测试。

9. 过去，使用OpenGL就是在 immediate mode 立即模式（也称为固定功能管线）下开发，该模式容易操控，但是不够高效。所以官方开始从3.2版本不建议使用立即模式，转而使用 core-profile 模式，它是一个新的版本，移除了所有的旧的不推荐的功能。

10. 当使用core-profile模式时，如果尝试使用不推荐的功能，会报错。这对初学者变得更难了。

11. 为了保持向下兼容性，OpenGL从来没有删除过任何一个功能。不过随着硬件结构的改变，OpenGL3.1开始抛弃一些api，即提供商可以不为这些API提供实现。抛弃的api变成了一个扩展。

12. OpenGL允许提供商通过它的扩展机制进行创新。提供商向OpenGL标准管理组织注册他们的扩展，从而被分配一个编号，避免重复。

13. glew，不同的显卡公司，也会发布一些只有自家显卡才支持的扩展函数，你要想用这数函数，不得不去寻找最新的glext.h,有了GLEW扩展库，你就再也不用为找不到函数的接口而烦恼，因为GLEW能自动识别你的平台所支持的全部OpenGL高级扩展函数。

13. GLEW是用来管理OpenGL的函数指针的，所以在调用任何OpenGL的函数之前我们需要初始化GLEW。

14. glfw是继glut，freeglut之后，用来创建OpenGL上下文和窗口管理的第三方库。因为OpenGL不包含任何窗口创建和用户交互的函数。

15. CMake是用来生成不同的工程文件的，例如VS2010，VS2013等

16. 配置开发环境需要在三个地方：

    1. 项目属性→C/C++→一般→附加包含目录。         头文件的位置。
    2. 项目属性→链接器→常规→附加库目录。            .lib文件的目录。
    3. 项目属性→链接器→输入→附加依赖项。             要连接的.lib文件的名字。

17. glewhe glfw一般使用静态库连接。引入glew32s.lib和glfw3.lib

18. 要先include glew，然后再引入窗口管理库glfw。因为glew会引入一些例如gl.h的基本库。

19. glfw的函数在使用前需要先初始化，第一个init函数返回GL_TRUE或GL_FALSE，表示初始化成功与否。

20. ```c
    glfwInit();
    glfwWindowHint(GLFW_CONTEXT_VERSION_MAJOR, 3);
    glfwWindowHint(GLFW_CONTEXT_VERSION_MINOR, 3);
    glfwWindowHint(GLFW_OPENGL_PROFILE, GLFW_OPENGL_CORE_PROFILE);
    ```

21. 查看当前OpenGL的版本：

    ```c
    #include <stdio.h>
    //#define GLEW_STATIC  //静态链接才需要
    #include <GL/glew.h>
    #include <GLFW/glfw3.h>
    
    void framebuffer_size_callback(GLFWwindow* window, int width, int height);
    void key_callback(GLFWwindow* window, int key, int scancode, int action, int mode);
    
    int main() {
    
    	//初始化glfw
    	glfwInit();
    	glfwWindowHint(GLFW_CONTEXT_VERSION_MAJOR, 3);
    	glfwWindowHint(GLFW_CONTEXT_VERSION_MINOR, 3);
    	glfwWindowHint(GLFW_OPENGL_PROFILE, GLFW_OPENGL_CORE_PROFILE);
    
    	//使用glfw打开一个窗口
    	GLFWwindow *window = glfwCreateWindow(800, 600, "learnopengl", NULL, NULL);//创建一个800x600的窗口，名称为learnopengl
    	if (window == NULL) {
    		printf("初始化窗口失败\n");
    		glfwTerminate();   //释放资源
    		return	-1;
    	}
    	glfwMakeContextCurrent(window);//将刚才创建的window作为当前线程的主上下文
    
    	glewExperimental = GL_TRUE;   //开启实验性功能,GLEW在管理OpenGL的函数指针时更多地使用现代化的技术
    	if (glewInit() != GLEW_OK) {  //初始化glew
    		glfwTerminate();
    		return -1;
    	}
    
    	glViewport(0, 0, 800, 600); //设置OpenGL渲染视口的位置和大小，是相对于窗口的
    	glfwSetFramebufferSizeCallback(window, framebuffer_size_callback);//注册这个回调函数，它会在每次窗口大小改变时自动被调用。
    	glfwSetKeyCallback(window, key_callback);
    	while (!glfwWindowShouldClose(window)) {  //进行渲染循环，检测是否要关闭窗口
    		glClearColor(0, 0.5f, 0.5f, 1.0f);//设置要清屏的颜色RGBA。每次渲染循环的开始都进行清屏,否则我们仍能看见上一次迭代的渲染结果
    		glClear(GL_COLOR_BUFFER_BIT);//清除颜色缓冲区
    		glfwSwapBuffers(window);   //交换显示和绘制缓冲区
    		glfwPollEvents();        //进行事件处理，键盘鼠标等。
    	}
    	glfwTerminate();
    	return 0;
    }
    //当窗口大小改变时，视口也应该跟着改变，这个函数用来重置视口的大小。
    void framebuffer_size_callback(GLFWwindow* window, int width, int height){
    	glViewport(0, 0, width, height);
    }
    void key_callback(GLFWwindow* window, int key, int scancode, int action, int mode){
    	// 当用户按下ESC键,我们设置window窗口的WindowShouldClose属性为true
    	// 关闭应用程序
    	if (key == GLFW_KEY_ESCAPE && action == GLFW_PRESS)
    		glfwSetWindowShouldClose(window, GL_TRUE);
    }
    ```
    
22. 回调函数一般在创建窗口后，渲染循环前注册。可以用来对键盘的鼠标的动作进行处理。

23. 如果使用单缓冲来绘制图片，会出现闪烁，这是因为绘制也需要时间，通常是从左向右，从上往下。为了克服这种问题，一般会使用双缓冲，前缓冲是最终显示在屏幕上的图像，所有的渲染命令都作用在后缓冲，当渲染结束时，切换前后缓冲，这样画面是瞬间呈现的，没有之前的问题。

24. hint函数可以对接下来要创建的窗口进行参数设置，接受两个int值，第一个为要设置的参数从GLFW_开头的枚举值中选取。

25. 指定版本的好处是当用户电脑中的OpenGL版本不满足要求的时，无法启动。

26. OpenGL的一大特性就是对扩展(Extension)的支持，当一个显卡公司提出一个新特性或者渲染上的大优化，通常会以扩展的方式在驱动中实现。通过这种方式，开发者不必等待一个新的OpenGL规范面世，就可以使用这些新的渲染特性了，只需要简单地检查一下显卡是否支持此扩展。通常，当一个扩展非常流行或者非常有用的时候，它将最终成为未来的OpenGL规范的一部分。

27. 使用扩展的代码大多看上去这样子：

28. ```c
    if(GL_ARB_extension_name){
        // 使用硬件支持的全新的现代特性
    }else{
        // 不支持此扩展: 用旧的方式去做
    }
    ```

# 进阶

1. OpenGL自身是一个巨大的状态机， OpenGL的状态通常被称为OpenGL上下文(Context)。通过修改context来控制渲染的方式。通过bind的操作将以下对象绑定到context，指定为当前要操作的对象。OpenGL还有一些可以开关的功能，例如剔除面，使用glEnable。可以对鼠标键盘事件进行处理，来修改OpenGL状态机。

2. 状态机有多个接口，可以绑定一下几种对象，一种对象同时只能绑定一种。OpenGL的操作大多是只指定接口的。接口会默认调用绑定到它上面的对象。

   1. VAO    glBindVertexArray(VAO)
   2. EBO    glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, EBO)
   3. VBO    glBindBuffer(GL_ARRAY_BUFFER, VBO)

3. OpenGL库是用C语言写的，同时也支持多种语言的派生，但其内核仍是一个C库。由于C的一些语言结构不易被翻译到其它的高级语言，因此OpenGL开发的时候引入了一些抽象层。

4. ```c
   // 创建对象
   unsigned int objectId = 0;
   glGenObject(1, &objectId);
   // 绑定对象至上下文
   glBindObject(GL_WINDOW_TARGET, objectId);
   // 设置当前绑定到 GL_WINDOW_TARGET 的对象的一些选项
   glSetObjectOption(GL_WINDOW_TARGET, GL_OPTION_WINDOW_WIDTH, 800);
   glSetObjectOption(GL_WINDOW_TARGET, GL_OPTION_WINDOW_HEIGHT, 600);
   // 将上下文对象设回默认
   glBindObject(GL_WINDOW_TARGET, 0);
   ```

5. 创建对象时，将对象ID存储为一个整数，以后用该整数代表该对象。类似于句柄。然后将对象绑定到窗口，再设置窗口的选项，最后解绑对象，此时刚才设置的选项并没有丢失，而是保存在了句柄对应的对象中了。下回再要使用时，再绑定即可。

# 渲染管线

1. OpenGL中的世界是3D的，但是屏幕和窗口是2D的，所以OpenGL的工作是将3D的世界投影到2D上，保证纵深关系正确。这一过程由图形管线管理的。主要分为两部分①根据相机，将3D坐标转为2D坐标，即顶点变换②将2D坐标转为2D色彩像素，计算坐标和像素点的对应，即光栅化。2D坐标是精准表示，2D像素是近似表示，受限于屏幕分辨率，分辨率越高，二者越接近。
2. 管线功能分为多个步骤，上一步的输出又作为下一步的输入。这些步骤可以并行处理，所以显卡一般有较多的处理器核心，上千个。在GPU运行的程序称作shaders，着色器。可以重写着色器以替代默认的，因而可以精细地控制GPU。着色器使用GLSL语言来开发。
3. shader不仅仅可以做着色。
4. 蓝色的部分是可以自定义的，顶点和片段着色器（主要的工作内容是操纵该着色器）OpenGL中没有默认的，几何着色器有默认的。
5. ![The OpenGL graphics pipeline with shader stages](计算机图形学和OpenGL.assets/pipeline.png) 
6. 形状着色器连接点线面，装配成图元，几何着色器可以在现有的线面上插入点，线，精细化模型，曲面细分会用到，不过一般很少会修改。
7. 光栅化之前的模型都是在$[1-,1]^3$之间的，光栅化时要考虑屏幕的分辨率。该着色器生成供片段着色器使用的片段，会执行裁切，丢弃超出视图的所有像素，用来提升效率。
8. 片段着色器的目的是计算一个图元上像素的最终颜色，这也是所有高级效果产生的地方，光照，阴影，纹理都在此设置。OpenGL中的一个片段是OpenGL渲染一个像素所需的所有数据。
9. 最后是alpha测试和混合阶段，主要检测片段的深度值，确定前后顺序，后面的会被丢弃。此时还会检查alpha值（物体的透明度），进行混合。
10. 主要工作是将顶点数据转化为像素。可以认为一个顶点包含坐标和颜色属性，实际包含的比这个多。
11. 除了给出顶点，还要给定这些顶点是用来构成点云，线还是面等等的设置。
12. 一旦你的顶点坐标已经在顶点着色器中处理过，它们就应该是标准化设备坐标，NDC了，标准化设备坐标是一个x、y和z值在-1.0到1.0的一小段空间。任何落在范围外的坐标都会被丢弃/裁剪，不会显示在你的屏幕上。 坐标轴的方向：x轴水平向右，y轴竖直向上，z轴表示深度，表示像素在空间中离你的距离。（0，0）在图像的中心。NDC之后会变成屏幕设备坐标，通过视口变换glViewport()完成。

# 顶点数据

1. OpenGL是一个3D图形库，模型的所有坐标都是3维的。

2. 一般先用3D建模软件建立各种模型，导出obj文件（包含顶点坐标，法向量，纹理，每个面的各个的顶点编号，法向量编号，纹理坐标等），在编写程序将obj文件读取成紧凑的数组，这之前都是在CPU中完成的工作。

3. v一行表示顶点，vt一行表示纹理坐标u,v值，vn一行是法向量，f一行表示一个面，每一段是一个顶点编号/纹理编号/法向量编号。定义平面时，可以只定义1个法向量，所有的点共用一个法向量。这样的话结点坐标不包含法向量，可以简化。

4. ![image-20210523153047253](计算机图形学和OpenGL.assets/image-20210523153047253.png)

5. CPU（一次性大量的）发送数据到VBO顶点缓冲对象（在GPU的显存中，）。然后使用VAO，VAO里有16个栏位，每个都存储着如何解析VBO中的数据，变成顶点着色器可以使用的形式。一般来说一个模型使用一个VAO。同一时刻只能有一个VAO在工作。

6. 使用缓冲对象的好处是可以一次性发送大量数据，从CPU发送到GPU的速度相对较慢，所以尽可能地一次性多发送些。顶点着色器访问显存的速度非常快，因为他们都是在GPU内部。

7. VBO是一种OpenGL对象，所有的VBO具有一个独一无二的ID。使用glGenBuffers来生成，可以一次性生成多个。

8. ```c
   unsigned int VBO;
   glGenBuffers(1, &VBO);  //一次生成一个VAO
   
   unsigned int VAO[10];
   glGenVertexArrays(10, VAO);   //一次生成10个VAO
   ```

9. VAO可以关联两种buffer，array buffer和element buffer。

10. OpenGL有许多缓冲对象类型，VBO属于GL_ARRAY_BUFFER，OpenGL的Context可以同时绑定多个缓冲，只要类别不同。glBindBuffer用来把缓冲对象VBO绑定到Context的GL_ARRAY_BUFFER上。此后，使用任何GL_ARRAY_BUFFER上的缓冲调用，都会使用绑定的VBO。

11. ```c
    glBindBuffer(GL_ARRAY_BUFFER, VBO);
    ```

12. 使用glBufferData把之前定义的顶点数据vertices数组传送到OpenGL的内存中。该函数专门用来把用户自定义的数据复制到当前绑定的缓冲中。第一个参数是目标缓冲的类型，第二个是传输的数据大小（单位为字节），第三个是实际的数据的地址，此处是数组名，最后一个参数制定了显卡如何管理给定的数据。这个设定会决定显卡是否把数据放在高速缓存中。

13. ```c
    glBufferData(GL_ARRAY_BUFFER, sizeof(vertices), vertices, GL_STATIC_DRAW);
    ```

    1. GL_STATIC_DRAW ：数据不会或几乎不会改变。
    2. GL_DYNAMIC_DRAW：数据会被改变很多。
    3. GL_STREAM_DRAW ：数据每次绘制时都会改变。

14. 着色器本质上一段程序，需要编译。

15. 在真实的程序中，输入数据通常不是NDC，所以必须要先转化到可视区域内，这个操作应该在顶点着色器中完成。

16. 该着色器采用运行时动态编译。源代码储存在一个字符串内。

17. 下一步创建顶点着色器，和buffer对象不同，1次只能创建1个。

18. ```c
    unsigned int vertexShader;
    vertexShader = glCreateShader(GL_VERTEX_SHADER);//创建顶点着色器对象
    glShaderSource(vertexShader, 1, &vertexShaderSource,NULL);//为着色器指定源代码,第一个参数为要绑定源码的着色器，第二个参数是源码的字符串数量，第三个参数是源码的地址，
    glCompileShader(vertexShader);//编译着色器
    ```

19. 用下面的代码，glGetShaderiv检查编译着色器是否成功。glGetShaderInfoLog来检查输出的日志。

20. ```c
    int  success;
    char infoLog[512];
    glGetShaderiv(vertexShader, GL_COMPILE_STATUS, &success); //success结果为1表示编译成功。
    if (!success){
        glGetShaderInfoLog(vertexShader, 512, NULL, infoLog);
    	printf("ERROR::SHADER::VERTEX::COMPILATION_FAILED:%s\n",infoLog);
    }
    ```
    
21. 要使用shader之前，必须将其链接到shader program上，然后激活该shader program，已激活着色器程序的shader会在渲染时被调用。

22. ```c
    unsigned int shaderProgram;
    shaderProgram = glCreateProgram();  //创建一个shader program
    glAttachShader(shaderProgram, vertexShader);  //将shader附着到shader program
    glAttachShader(shaderProgram, fragmentShader);
    glLinkProgram(shaderProgram);//链接shader program
    glUseProgram(shaderProgram);//激活shader program
    glDeleteShader(vertexShader);//链接完shader program之后，就可以删除shader了
    glDeleteShader(fragmentShader);
    ```

23. 当链接着色器至一个程序的时候，它会把每个着色器的输出链接到下个着色器的输入。当输出和输入不匹配的时候，你会得到一个链接错误。

24. 顶点着色器只能解析特定格式的数据，而从CPU传输到VBO中的数据，可以是任意格式的。这意味着我们指定如何解析VBO中的数据。

25. 顶点数据如下，结构如下图：

26. ```c
    float vertices[] = {   //这里，顶点数据只包括顶点的坐标这一属性，3个相邻的float类型表示1个点。
        -0.5f, -0.5f, 0.0f,
        0.5f, -0.5f, 0.0f,
        0.0f,  0.5f, 0.0f
    };
    ```

27. ![img](计算机图形学和OpenGL.assets/vertex_attribute_pointer.png) 

28. 由于在顶点着色器中讲VAO的0号顶点属性解析出的数据当做了顶点的位置。

29. glVertexAttribPointer()告诉OpenGL如何解析VBO中的数据。把整串的数据应用到各个顶点的属性上。

30. ```c
    glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 3 * sizeof(float), (void*)0);//默认从调用该函数前绑定到Context的GL_ARRAY_BUFFER接口的VBO中读取。
    glEnableVertexAttribArray(0);
    ```

    1. 第一个参数指定要配置的顶点属性，此处为0，对应于之前的layout(location = 0)。
    2. 第二个和第三个参数指定一个顶点属性如何解析，由于在vertexShader中定义了输入变量类型为vec3，所以此处为3个GL_FLOAT。
    3. 第四个参数是是否要对数据进行标准化操作，如果是，则所有的数据会被映射到[0,1]，如果是有符号数，则是[-1,1]。
    5. 第五个参数是步长，指的是连续顶点属性组之间的间隔。不一定是第2和3个参数组合的值，因为有时候同一种顶点属性不是连续排列的，比如顶点位置之后就是法向量，然后是颜色，再后面才是下一个顶点的位置，所以需要跳过一定的数据读取。
    6. 最后一个参数进行了强制类型转换，表示从VBO的哪里开始读取，即起始偏移量。

31. 该函数并没有指定要解释的数据在哪，因为它默认去解析绑定到GL_ARRAY_BUFFER的VBO中的数据。

32. glEnableVertexAttribArray()这个函数以顶点属性位置值作为参数，启用顶点属性，默认是禁用的。

33. 每绘制一个对象都要进行如下步骤，显然比较繁琐，可以将这些设置和顶点数组对象VAO关联起来更方便使用。

34. ```c
    // 0. 复制顶点数组到缓冲中供OpenGL使用
    glBindBuffer(GL_ARRAY_BUFFER, VBO);
    glBufferData(GL_ARRAY_BUFFER, sizeof(vertices), vertices, GL_STATIC_DRAW);
    // 1. 设置顶点属性指针
    glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 3 * sizeof(float), (void*)0);
    glEnableVertexAttribArray(0);
    // 2. 当我们渲染一个物体时要使用着色器程序
    glUseProgram(shaderProgram);
    // 3. 绘制物体
    someOpenGLFunctionThatDrawsOurTriangle();
    ```

35. OpenGL的核心模式要求使用VAO，这样才能知道如何处理用户的顶点输入。

36. VAO可以向VBO一样被绑定到Context中，任何随后的顶点属性调用，都会存储在这个VAO中，这样不同的顶点数据和属性配置非常方便，只需要切换绑定VAO即可。

37. 一个顶点数组对象会储存以下这些内容：

    1. glEnableVertexAttribArray和glDisableVertexAttribArray的调用。即启用的顶点属性。顶点属性默认是禁用的。
    2. 通过glVertexAttribPointer设置的顶点属性配置。
    3. 通过glVertexAttribPointer调用与顶点属性关联的顶点缓冲对象。

38. context可以切换绑定到它上面的VAO（如何解析数据），和VBO（数据）。还有shader program。来显示不同的模型。

39. <img src="计算机图形学和OpenGL.assets/image-20210523220228216.png" alt="image-20210523220228216" style="zoom:67%;" />

40. ![img](计算机图形学和OpenGL.assets/vertex_array_objects_ebo.png)  

41. 创建1个VAO对象：

    ```c
    unsigned int VAO;
    glGenVertexArrays(1, &VAO);  //此方法支持创建多个。
    ```

43. 一般当你打算绘制多个物体时，你首先要生成/配置所有的VAO（和必须的VBO及属性指针)，然后储存它们供后面使用。当我们打算绘制物体的时候就拿出相应的VAO，绑定它，绘制完物体后，再解绑VAO。

44. 配置实例：

    ```c
    //创建VAO并绑定，然后再进行顶点数据和属性设置。
    unsigned int VAO ,VBO;
    glGenVertexArrays(1, &VAO);
    glBindVertexArray(VAO);
    //创建VBO，绑定到GL_ARRAY_BUFFER，将预定的数组存储到VBO中
    glGenBuffers(1, &VBO);  //类似于malloc，申请内存
    glBindBuffer(GL_ARRAY_BUFFER, VBO);
    glBufferData(GL_ARRAY_BUFFER, sizeof(vertices), vertices, GL_STATIC_DRAW);
    //配置顶点属性解析器
    glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 3 * sizeof(float), (void*)0);
    glEnableVertexAttribArray(0);
    glBindBuffer(GL_ARRAY_BUFFER, 0);//解绑VBO，因为在glVertexAttribPointer()中已经把对应的VBO注册为顶点属性的缓冲对象了
    glBindVertexArray(0);//解绑VAO，避免其他的操作影响到VAO中存储的设置。
    ```

45. 以下使用的draw函数，顶点都是来自使用VAO的顶点属性解析VBO出来的。只有到这一步才真正开始绘制，向帧缓冲写入内容，等待下一次swap。

46. glDrawArrays()函数第一个参数为要绘制的图元类型，第二个参数为顶点数组的起始索引，最后一个参数为要绘制的顶点个数。

47. ```c
    glUseProgram(shaderProgram);
    glBindVertexArray(VAO);
    glDrawArrays(GL_TRIANGLES, 0, 3);//绘制一个三角形，从第0个顶点开始，一共绘制3个顶点。如果要绘制两个三角形，则应将最后一个参数修改为6。
    ```

48. 一般来说消息循环中，应先处理用户的输入，然后渲染，最后再获取用户输入，这样可以减少输入的卡顿。glfwPollEvents函数会处理用户的输入，一个键按下抬起会形成两个消息，逐个处理。这里边对OpenGL状态机的设置都只能等到下一次glfwSwapBuffers时才能被看到。

49. OpenGL最擅长画三角形，但是使用glDrawArray方法绘制三角形时，公共角点需要重复定义（例如两个相邻的三角形需要6个顶点，其实只要4个就够），浪费内存和VBO的空间。

50. 可以使用EBO来对点做索引，避免重复定义。EBO也是一个缓冲对象，类型:GL_ELEMENT_ARRAY_BUFFER，因此需使用要bufferdata从CPU传入到GPU中。

50. glDrawElements按照（当前绑定到Context的GL_ELEMENT_ARRAY_BUFFER接口的EBO）索引绘图，第一个参数是要绘制的图元类型，第二个参数是要绘制的顶点个数，第三个参数是索引的类型，使用GL_UNSIGNED_INT，不能使用unsigned int或GLuint，因为那些都是关键字，只能用于定义，而这个是用来标记的，是一个枚举值。最后一个参数是EBO中的起始偏移量。

    ```c
    glDrawElements(GL_TRIANGLES, 6, GL_UNSIGNED_INT, 0);
    ```

53. 当没有EBO，使用drawArray绘制图元时，只能按照顶点的顺序来构成图元。而使用EBO+drawElements可以按照EBO的索引顺序来构成图元。不过二者都需要使用VBO对象。

54. 以上可以看出每次要用索引渲染物体时，都要绑定EBO，有点麻烦，因此开发出了VAO来保存EBO的状态。VAO绑定时正在绑定的索引缓冲对象会被保存为VAO的元素缓冲对象。绑定VAO的同时也会自动绑定EBO。因此解绑VAO前应先解绑EBO。 每个VAO都有只一个EBO。

55. OpenGL中三角形顶点顺序使用右手定则可以确定面的法线，如果面的法线具有+Z分量，则该面是正面。默认是正反面都绘制。

56. ```c
    glEnable(GL_CULL_FACE);   //开启剔除面的功能
    glCullFace(GL_BACK);   //剔除背面。即如果面的法线具有-Z分量的，则不会绘制该面
    glPolygonMode(GL_FRONT_AND_BACK, GL_LINE); //以线框模式绘制正面的和背面。
    ```

# 着色器

1. Shader是运行在GPU上的小程序。作用时把输入转化成输出。着色器之间只能通过输入输出沟通。

2. GLSL是类C语言，为图形计算量身定制的，包含一些针对矩阵和向量的操作。

3. 着色器先要声明版本，然后是输入输出变量，uniform和main函数，每个着色器的入口点都是main函数，在其中处理输入，构建输出。

4. ```glsl
   #version version_number
   in type in_variable_name;
   in type in_variable_name;
   
   out type out_variable_name;
   
   uniform type uniform_name;
   
   int main(){
     // 处理输入并进行一些图形操作
     ...
     // 输出处理过的结果到输出变量
     out_variable_name = weird_stuff_we_processed;
   }
   ```
   
5. 顶点着色器源代码如下：它必须要输出顶点位置

6. ```glsl
   #version 330 core  //声明GLSL版本号，这个版本号要和OpenGL匹配的，同时声明使用核心模式。
   layout (location = 0) in vec3 aPos;  //in关键字设定着色器的输入变量。用VAO的0号顶点属性读取VBO中的数据，赋值给aPos这个vec3类型的变量。
   out vec4 vertexColor;
   void main(){
       gl_Position = vec4(aPos.x, aPos.y, aPos.z, 1.0f); //顶点着色器预定义的输出，vec4类型，要把输入的vec3类型的数据添加w分量，变成齐次坐标，最后补1表示点，补0表示向量。这是最简单的顶点着色器。
       vertexColor=vec4(1.0f,0.5f,0.8f,1.0f);
   }
   ```
   
7. 片元着色器的源代码如下：它必须要输出片元的颜色。

   ```glsl
   #version 330 core
   out vec4 FragColor;//out关键字，设定着色器的输出变量。该着色器需要输出一个四维的向量，名称无所谓。
   in vec4 vertexColor;
   void main(){
       FragColor = vertexColor;  //设置片元着色器输出的每个像素的颜色,OpenGL使用RGBA的颜色空间，每个强度分量在0.0-1.0之间。
   } 
   ```
   
8. GLSL中一个向量可以有1，2，3或4个分量，vec.x，vec.y，vec.z，vec.w。除了一些和C语言一样的基础数据类型意外，GLSL还提供了两种容器类型，向量和矩阵。大多数情况下float就够了，不用double。

9. ![image-20210523232438213](计算机图形学和OpenGL.assets/image-20210523232438213.png)

10. 向量的构造：

    ```glsl
    vec2 someVec;
    vec4 differentVec = someVec.xyxx;     //将someVec的x，y，x，x组成一个四维数据。
    vec3 anotherVec = differentVec.zyw;
    vec4 otherVec = someVec.xxxx + anotherVec.yxzy;
    
    vec2 vect = vec2(0.5, 0.7);
    vec4 result = vec4(vect, 0.0, 0.0);
    vec4 otherResult = vec4(result.xyz, 1.0);
    ```

11. 顶点着色器中每个输入变量又叫做顶点属性，一般有16个，由硬件决定。OpenGL确保有16个包含4分量的顶点属性可用。属性一般有位置，颜色，法向量，纹理坐标等等。可以使用location来指定从哪里获得输入变量。 layout (location = 0) 。

12. 如果打算从一个着色器向另一个着色器发送数据，则必须在发送方着色器中声明一个输出，在接收方着色器中声明一个同类型同名称的输入。只有类型和名字都一样的时候，OpenGL就会把两个变量链接到一起，它们之间就能发送数据了。

13. CPU如果要传送顶点数据以外的数据（例如时间）给shader，就需要通过uniform变量输入。uniform是CPU的应用向GPU的着色器发送数据的一种方式。uniform变量是全局的，不能重复，可以被着色器程序在任意着色器在任意阶段使用。

14. ```c
    GLfloat time = glfwGetTime();//返回从从程序开始运行到当前一共经历的秒数
    GLfloat greenValue = sin(time) / 2.0f + 0.5f;
    int vertexColorUniform = glGetUniformLocation(shaderProgram, "ourColor");  //第一个参数指定要从哪个shader program中获取uniform变量，第二个参数为uniform变量的名称
    glUseProgram(shaderProgram); //查询uniform地址不要求之前使用过着色器程序，但是更新一个uniform之前你必须先使用程序（调用glUseProgram)，因为它是在当前激活的着色器程序中设置uniform的。
    glUniform4f(vertexColorUniform, 0.0f, greenValue, 0.0f, 1.0f);
    ```

15. 读取如下的顶点数据：

    ```c
    float vertices[] = {
    	-0.5f, -0.5f, 0.0f,1.0f,0,0,  //0
    	0.5f, -0.5f, 0.0f,0.0f,1.0f,0.0f,   //1
    	0.0f, 0.5f, 0.0f,0.0f,0.0f,1.0f,   //2
    	0.8f, 0.8f, 0.0f,1.0f,1.0f,1.0f   //3
    };
    glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 6 * sizeof(float), (void*)0);
    glEnableVertexAttribArray(0);
    glVertexAttribPointer(1, 3, GL_FLOAT, GL_FALSE, 6 * sizeof(float), (void*)(3 * sizeof(float)));
    glEnableVertexAttribArray(1);
    ```

16. vertex shader：

    ```glsl
    #version 330 core
    layout (location = 0) in vec3 aPos;
    layout (location = 1) in vec3 aColor;
    out vec4 vertexColor;
    void main(){
    	gl_Position = vec4(aPos.x, aPos.y, aPos.z, 1.0f);
    	vertexColor=vec4(aColor,1.0f);
    }
    ```

17. fragment shader：

    ```glsl
    #version 330 core
    out vec4 FragColor;
    in vec4 vertexColor;
    uniform vec4 ourColor;
    void main(){
    	FragColor = vertexColor;
    }
    ```

18. 将shader写在单独的文件中，在main函数中，读取到字符串中：

    ```c
    #include "shader.h"
    #include <stdio.h>
    #include <stdlib.h>
    #include <string.h>
    
    char *  shaderLoad(const char *shaderPath) {
    	FILE *fp = NULL;
    	char *str = NULL;
    	fopen_s(&fp,shaderPath, "r");//如果使用fread进行二进制读取，那么文件也应以二进制形式打开。不过这这样会多读出来\r，编译不通过。
    	if (fp == NULL ) {
    		printf("打开失败\n");
    		return NULL;
    	}
    
    	fseek(fp, 0, SEEK_END);
    	int file_size = ftell(fp); //获取文件的大小。
    	fseek(fp, 0, SEEK_SET);
    	str = malloc((file_size+1) * sizeof(char));  //分配内存空间，多一个字节用来存储尾零。
    	memset(str, 0, file_size + 1);//由于实际读取到的字节数要少于文件大小，因此需要手动添加尾0。
    	fread_s(str, file_size + 1, file_size, 1, fp);
    	return str;
    }
    ```

19. 一个常见的错误是，将放大过滤的选项设置为多级渐远纹理过滤选项之一。这样没有任何效果，因为多级渐远纹理主要是使用在纹理被缩小的情况下的：纹理放大不会使用多级渐远纹理，为放大过滤设置多级渐远纹理的选项会产生一个GL_INVALID_ENUM错误代码。

24. GLSL中的数学运算：

25. 向量和向量乘法可以用dot(a,b)，cross(a,b)来计算内积和外积。而a*b是进行元素对应乘法。
